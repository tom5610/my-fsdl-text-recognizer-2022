{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tom5610/my-fsdl-text-recognizer-2022/blob/main/lab01/notebooks/c_lab01_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKfcRGYnyOxY"
      },
      "source": [
        "Lab 01: Deep Neural Networks in PyTorch\n",
        "\n",
        "Objective:\n",
        "* how to write a basic neural network from scatch in PyTorch\n",
        "* How the submodules of torch, like `torch.nn` and `torch.utils.data`, make writing performant neural network training and inference code easier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRH_STeCygfM"
      },
      "source": [
        "## Setup\n",
        "Below cell will run full environment setup in colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/tomlu/Workspace\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "PosixPath('/Users/tomlu/Workspace/my-fsdl-text-recognizer-2022/lab01')"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "cwd = Path.cwd()\n",
        "print(cwd)\n",
        "\n",
        "lab_idx = 1\n",
        "lab_name = f\"lab{str(lab_idx).zfill(2)}\"\n",
        "my_fsdl = \"my-fsdl-text-recognizer-2022\"\n",
        "os.chdir(f\"{cwd}/{my_fsdl}/{lab_name}\")\n",
        "\n",
        "Path.cwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNzmJtFVye94",
        "outputId": "e88d91c0-f79b-41eb-f806-877fafecbd4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: PYTHONPATH=.:/env/python\n",
            ".:/env/python\n",
            "/content/fsdl-text-recognizer-2022-labs/lab01\n",
            "\u001b[0m\u001b[01;34mnotebooks\u001b[0m/  \u001b[01;34mtext_recognizer\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "lab_idx = 1\n",
        "\n",
        "if 'bootstrap' not in locals() or bootstrap.run:\n",
        "    pythonpath, = !echo $PYTHONPATH\n",
        "    if '.' not in pythonpath.split(':'):\n",
        "        pythonpath = \".:\" + pythonpath\n",
        "        %env PYTHONPATH={pythonpath}\n",
        "        !echo $PYTHONPATH\n",
        "\n",
        "    # get both Colab and local notebooks into the same state\n",
        "    !wget --quiet https://fsdl.me/gist-bootstrap -O bootstrap.py\n",
        "    import bootstrap\n",
        "\n",
        "    bootstrap.change_to_lab_dir(lab_idx=lab_idx)\n",
        "\n",
        "    # allow 'hot-reloading' of modules\n",
        "    %load_ext autoreload\n",
        "    %autoreload 2\n",
        "    # needed for inline plots in some contexts\n",
        "    %matplotlib inline\n",
        "\n",
        "    bootstrap.run = False\n",
        "\n",
        "!pwd\n",
        "%ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACyi8BTcz1nk"
      },
      "source": [
        "## Getting data and making Tensors\n",
        "\n",
        "before we can build a model, we need data. \n",
        "\n",
        "Use MNIST dataset of handwritten digits.\n",
        "\n",
        "The data used to train state-of-the-art models these days is generally too large to be stored on the disk of any single machine (to say nothing of the RAM!), so fetching data over a network is a common first step in model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        " # allow 'hot-reloading' of modules\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "# needed for inline plots in some contexts\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iXAz4GGHzhy0"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path \n",
        "import requests\n",
        "\n",
        "def download_mnist(path):\n",
        "    url = \"https://github.com/pytorch/tutorials/raw/master/_static/\"\n",
        "    filename = \"mnist.pkl.gz\"\n",
        "\n",
        "    if not (path / filename).exists():\n",
        "        content = requests.get(url + filename).content\n",
        "        (path / filename).open(\"wb\").write(content)\n",
        "\n",
        "    return path / filename\n",
        "\n",
        "data_path = Path(\"data\") if Path(\"data\").exists() else Path(\"../data\")\n",
        "path = data_path / \"downloaded\" / \"vector-mnist\"\n",
        "path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "datafile = download_mnist(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IUZckCJG39Nn"
      },
      "outputs": [],
      "source": [
        "import gzip\n",
        "import pickle \n",
        "\n",
        "def read_mnist(path):\n",
        "    with gzip.open(path, \"rb\") as f:\n",
        "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")\n",
        "    return x_train, y_train, x_valid, y_valid\n",
        "\n",
        "x_train, y_train, x_valid, y_valid = read_mnist(datafile)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "c_qrmLb14ZHk"
      },
      "outputs": [],
      "source": [
        "import torch \n",
        "\n",
        "x_train, y_train, x_valid, y_valid = map(\n",
        "    torch.tensor, (x_train, y_train, x_valid, y_valid)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJa0EXhb4ywJ",
        "outputId": "06ef34bb-4d0c-42ec-b261-c1720e3c7e31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
            "tensor([5, 0, 4,  ..., 8, 4, 8])\n"
          ]
        }
      ],
      "source": [
        "print(x_train, y_train, sep=\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbrD0gYi5eP6",
        "outputId": "f59c0b65-2f98-483e-b3ec-07f0e6b4851e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(5),\n",
              " tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0117, 0.0703, 0.4922, 0.6836, 0.6484,\n",
              "         0.9648, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1172, 0.3672,\n",
              "         0.6641, 0.9883, 0.9883, 0.8789, 0.9883, 0.7617, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.9297, 0.9883, 0.9883, 0.9883, 0.9883, 0.3633,\n",
              "         0.3203, 0.1523, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8555,\n",
              "         0.9883, 0.9883, 0.7734, 0.9648, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.3125, 0.4180, 0.9883, 0.0430, 0.1680,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0039, 0.9883, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9883, 0.0078,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.7422, 0.2734, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1367,\n",
              "         0.8789, 0.4219, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9375, 0.9883, 0.0977, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.1758, 0.9883, 0.5859, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3633, 0.9883,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.9883, 0.2500, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1797, 0.7148,\n",
              "         0.9883, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.1523, 0.8945, 0.9883, 0.9766, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0938, 0.8633, 0.9883,\n",
              "         0.9883, 0.3047, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0898, 0.8320, 0.9883, 0.9883, 0.3164, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0703, 0.8555, 0.9883, 0.9883,\n",
              "         0.3125, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.2148, 0.8828, 0.9883, 0.9883, 0.5195, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5312, 0.9883, 0.8281, 0.5156,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000]))"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train[0], x_train[0, ::2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARnhmks_5muZ",
        "outputId": "99a7b931-9065-4438-952a-1f24d8a9f969"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2, 1)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.ndim, y_train.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inzqGjFF6Hj_",
        "outputId": "34ac8bc4-237e-4218-e9b2-f44346d1df1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([50000, 784])\n",
            "torch.Size([50000])\n"
          ]
        }
      ],
      "source": [
        "n, c = x_train.shape\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "id": "YGPKHIer6QvQ",
        "outputId": "0c9cd90f-a36f-4067-e8cc-ddf598506c8c"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'text_recognizer'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m/Users/tomlu/Workspace/my-fsdl-text-recognizer-2022/lab01/notebooks/c_lab01_pytorch.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tomlu/Workspace/my-fsdl-text-recognizer-2022/lab01/notebooks/c_lab01_pytorch.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrandom\u001b[39;00m \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tomlu/Workspace/my-fsdl-text-recognizer-2022/lab01/notebooks/c_lab01_pytorch.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwandb\u001b[39;00m \n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/tomlu/Workspace/my-fsdl-text-recognizer-2022/lab01/notebooks/c_lab01_pytorch.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtext_recognizer\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetadata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmnist\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmetadata\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tomlu/Workspace/my-fsdl-text-recognizer-2022/lab01/notebooks/c_lab01_pytorch.ipynb#X20sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m idx \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39mrandint(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(x_train))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tomlu/Workspace/my-fsdl-text-recognizer-2022/lab01/notebooks/c_lab01_pytorch.ipynb#X20sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m example \u001b[39m=\u001b[39m x_train[idx]\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'text_recognizer'"
          ]
        }
      ],
      "source": [
        "import random \n",
        "\n",
        "import wandb \n",
        "\n",
        "import text_recognizer.metadata.mnist as metadata\n",
        "\n",
        "idx = random.randint(0, len(x_train))\n",
        "example = x_train[idx]\n",
        "\n",
        "print(y_train[idx])\n",
        "wandb.Image(example.reshape(*metadata.DIMS)).image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4u1hTNXg9X8C"
      },
      "source": [
        "## Build a DNN using only `torch.Tensor` methods and Python\n",
        "\n",
        "### Defining the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9W3QEa8K7HP8"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "weights = torch.randn(784, 10) / math.sqrt(784)\n",
        "weights.requires_grad_()\n",
        "bias = torch.zeros(10, requires_grad=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKWAt2Nd-GFY",
        "outputId": "8da73c48-f955-427e-9088-d37043499a3e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2, torch.Size([784, 10]))"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weights.ndim, weights.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Mv6Lapqy-PRF"
      },
      "outputs": [],
      "source": [
        "def linear(x: torch.Tensor) -> torch.Tensor:\n",
        "    return x @ weights + bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWlrvcUtgFOz",
        "outputId": "e274198e-2216-48f9-e369-592ec665619f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.5742)\n",
            "tensor(0.5742)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(tensor([0.6208, 0.2513, 0.5182]), tensor([0.0318, 0.3594, 0.8958]))"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n = 3\n",
        "a = torch.rand(n)\n",
        "b = torch.rand(n)\n",
        "print(torch.matmul(a, b))\n",
        "print(a @ b)\n",
        "a, b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V91HqSTsgTvd",
        "outputId": "d3de4be9-055e-4711-fc26-4d58457260b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.40253448999999997"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "0.5367 * 0.0799 + 0.361 * 0.3948 + 0.3556 * 0.6106"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "xnit7vxEht4g"
      },
      "outputs": [],
      "source": [
        "a = torch.rand((3, 2))\n",
        "b = torch.rand((2, 2))\n",
        "result = a.mm(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIRk3B8rh8Ob",
        "outputId": "49bb48e7-a0bc-4d09-d1a6-f6eef91fd316"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[0.2096, 0.0723],\n",
              "         [0.4111, 0.4794],\n",
              "         [0.4698, 0.5032]]), tensor([[0.3150, 0.3239],\n",
              "         [0.4464, 0.0986]]), tensor([[0.0983, 0.0750],\n",
              "         [0.3435, 0.1804],\n",
              "         [0.3726, 0.2018]]))"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a, b, result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "jGQapurliM8t"
      },
      "outputs": [],
      "source": [
        "def log_softmax(x: torch.Tensor) -> torch.Tensor:\n",
        "    return x - torch.log(torch.sum(torch.exp(x), axis = 1))[:, None]\n",
        "\n",
        "def model(xb: torch.Tensor) -> torch.Tensor:\n",
        "    return log_softmax(linear(xb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YON-Yat8wQfs",
        "outputId": "4bc0b0b2-6929-469b-a3bd-ea7ab2bb58bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([-2.9019, -2.7442, -2.6731, -2.3839, -2.5940, -1.9546, -1.7174, -2.4605,\n",
            "        -2.4805, -1.8670], grad_fn=<SelectBackward0>) torch.Size([64, 10])\n"
          ]
        }
      ],
      "source": [
        "bs = 64 # batch size\n",
        "\n",
        "xb = x_train[0: bs] # a batch of inputs\n",
        "outs = model(xb)\n",
        "\n",
        "print(outs[0], outs.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32dBTixvxBJY"
      },
      "source": [
        "## Defining the loss and metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "X95ORSKUwjOI"
      },
      "outputs": [],
      "source": [
        "def accuracy(out: torch.Tensor, yb: torch.Tensor) -> torch.Tensor:\n",
        "    preds = torch.argmax(out, dim=1)\n",
        "    #print('accuracy comparison - ', (preds == yb).float())\n",
        "    return (preds == yb).float().mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bSqnMiVxST8",
        "outputId": "6c97810f-07e6-44b6-896c-9ec0695b11c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy comparison -  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 0., 1., 0., 0., 0., 0., 0., 1.])\n",
            "tensor(0.1094)\n"
          ]
        }
      ],
      "source": [
        "yb = y_train[0: bs]\n",
        "\n",
        "acc = accuracy(outs, yb)\n",
        "\n",
        "print(acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "bv4w1lzTxXsl"
      },
      "outputs": [],
      "source": [
        "def cross_entropy(output: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
        "    return -output[range(target.shape[0]), target].mean()\n",
        "\n",
        "loss_func = cross_entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d5O5Xzwz9ZN",
        "outputId": "fce13026-b631-4751-96b7-f453cf31bd92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.2519, grad_fn=<NegBackward0>) tensor(2.3026)\n"
          ]
        }
      ],
      "source": [
        "print(loss_func(outs, yb), -torch.log(torch.tensor(1 / 10)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlUw1Xs60Byd",
        "outputId": "9cc2b153-162d-4ce8-e388-a0ee2ecc16ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(-2.3026)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.log(torch.tensor(1 / 10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "u2Hsq9960HKZ"
      },
      "outputs": [],
      "source": [
        "loss = loss_func(outs, yb)\n",
        "\n",
        "loss.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeBo3jhF0bLA",
        "outputId": "676dad1f-c43a-4f53-8531-76483b00c7e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
              " tensor([-0.0011, -0.0529,  0.0256, -0.0021, -0.0255,  0.0595,  0.0155, -0.0051,\n",
              "          0.0027, -0.0166]))"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weights.grad, bias.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALffB6Yt0zaF"
      },
      "source": [
        "## Defining and running the fitting loop\n",
        "\n",
        "We now have all the ingredients we need to fit a neural network to data:\n",
        "\n",
        "* data (x_train, y_train)\n",
        "* a network architecture with parameters (model, weights, and bias)\n",
        "* a loss_func to optimize (cross_entropy) that supports .backward computation of gradients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "z7XzK1Io0iTo"
      },
      "outputs": [],
      "source": [
        "lr = 0.5\n",
        "epochs = 2\n",
        "\n",
        "for epoch in range(epochs): # loop over the data repeatedly\n",
        "    for ii in range((n - 1) // bs + 1):\n",
        "        start_idx = ii * bs\n",
        "        end_idx = start_idx + bs\n",
        "\n",
        "        # pull batches from x and from y\n",
        "        xb = x_train[start_idx:end_idx]\n",
        "        yb = y_train[start_idx:end_idx]\n",
        "\n",
        "        # run model\n",
        "        pred = model(xb)\n",
        "\n",
        "        # get loss\n",
        "        loss = loss_func(pred, yb)\n",
        "\n",
        "        # calculate the gradients with a backwards pass\n",
        "        loss.backward()\n",
        "\n",
        "        # update the parameters\n",
        "        with torch.no_grad(): # we don't want to track gradients through this part!\n",
        "            # SGD learning rule: update with negative gradient scaled by lr\n",
        "            weights -= weights.grad * lr\n",
        "            bias -= bias.grad * lr\n",
        "\n",
        "            # achtung: PyTorch doesn't assume you're done with gradients\n",
        "            #.         until you say so -- by explicitly \"deleting\" them. i.e. setting the gradients to 0.\n",
        "            weights.grad.zero_()\n",
        "            bias.grad.zero_()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-LYqR5M2bld",
        "outputId": "fa0c8ec9-7b29-4cac-f4b9-e536bddbe666"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy comparison -  tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
            "        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "tensor(0.9472, grad_fn=<NegBackward0>) tensor(0.8281)\n"
          ]
        }
      ],
      "source": [
        "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "id": "n28GLemQ27aX",
        "outputId": "5cbc1f86-b638-4e91-f3da-9841ad875f78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(4)\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAB8klEQVR4nO2Vz6spYRjHn7lJTJFfZUHUZMHKTjRhI5OVLVnYiD9hyj+h7GTLQimxEVkJWdA0K1kMHSULSUKReO5iuifXnHPMzVncuve7eud9vs9nvm/vO+8A/NMiXuw3mUwOhwMAhsPhd+QBAIBKpYKItVrtfvLHK0Sz2Wy1WgFAq9W+FO1eYszL5ZLJZL4N2uv1EJHn+T/o0el0arX6s2okErler4jIsqxcYjweFwThs3UZjUaO4xCxWCzabLaH6scbpVAoaJqmKCqVSimVSqkhFAoZDAYAGI/Hi8VCVsxYLDafzxGxXC5LoRaLpd/vI+JoNHK5XLKIGo2m0+kg4nK59Hq9UkMwGNzv94jo9/tlEQEgn88jIiKWSiVplSCIarUqGkwmkyxiOBwWBAEROY5zu91SQzQafX+lSqV6TrTb7ZPJBBG32y1N01IDRVGNRgMRN5uNz+eTFTOXy4kpOI5jGIZhmIew2WxWNKTTaVlE+PWF3Ot4PL7d6XA4iPP1el16PN/129Wn1+sDgUAymRQfXS6X0+n8sO10OrEsWygUzufzE+iDSJIkSVIcT6dT8bR3u91mswkArVaL5/nb7fbV2r9Wu91GxMFgkEgknprl3qe73Q4AVqtVuVx+apb7O/F4PARBzGaz9Xots+W//nr9BJb7AKlc0zBvAAAAAElFTkSuQmCC",
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=28x28 at 0x7F6A03E8BBD0>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "idx = random.randint(0, len(x_train))\n",
        "example = x_train[idx: idx+1]\n",
        "\n",
        "out = model(example)\n",
        "\n",
        "print(out.argmax())\n",
        "wandb.Image(example.reshape(28, 28)).image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "we4djKmg5ekB"
      },
      "source": [
        "## Refactoring with core `torch.nn` components\n",
        "\n",
        "\n",
        "### Using `torch.nn.functional` for stateless computation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "xJEDeN623W5-"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "loss_func = F.cross_entropy\n",
        "\n",
        "def model(xb):\n",
        "    return xb @ weights + bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBH72ULw52pw",
        "outputId": "85ac88c8-770f-4363-8582-bc231b140da1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy comparison -  tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
            "        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "tensor(0.9472, grad_fn=<NllLossBackward0>) tensor(0.8281)\n"
          ]
        }
      ],
      "source": [
        "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_k238jB96JLI"
      },
      "source": [
        "### Using torch.nn.Module to define functions whose state is given by `torch.nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "PyklJuFL5-jG"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class MNISTLogistic(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__() # this is mandatory as nn.Module does import setup\n",
        "        self.weights = nn.Parameter(torch.randn(784, 10) / math.sqrt(784))\n",
        "        self.bias = nn.Parameter(torch.zeros(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHgDmZiI03t7",
        "outputId": "57ad962d-8e65-4ba7-8348-3afe01b26136"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0.0634,  0.6026,  0.0680, -0.0123, -0.1119, -0.5882, -0.2499, -0.0625,\n",
            "         -0.1788, -0.3474],\n",
            "        [ 0.4817,  0.4657,  0.4165,  0.3899, -0.2445, -0.2347,  0.2087, -0.5309,\n",
            "         -0.8083, -0.4876],\n",
            "        [-0.0350,  0.2182,  0.2181,  0.1475, -0.1530,  0.2505, -0.5652, -0.1470,\n",
            "          0.0150, -0.0387],\n",
            "        [ 0.3391,  0.2915, -0.2129,  0.1553,  0.1105,  0.1131,  0.1531,  0.2332,\n",
            "         -0.3465,  0.3848]], grad_fn=<SliceBackward0>)\n",
            "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0033,  0.0038,  0.0024, -0.0262,  0.0029],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0044, -0.0054,  0.0255, -0.0229,  0.0032],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0432,  0.0080, -0.0154,  0.0134, -0.0162],\n",
            "        [ 0.0114, -0.0153, -0.0095,  0.0100,  0.0091],\n",
            "        [ 0.0036,  0.0032,  0.0024,  0.0018,  0.0016],\n",
            "        [-0.0352,  0.0425,  0.0653,  0.0017, -0.0267],\n",
            "        [ 0.0016,  0.0025, -0.0039,  0.0017,  0.0016],\n",
            "        [-0.0602,  0.0127, -0.0087,  0.0331, -0.0294],\n",
            "        [-0.0272,  0.0107, -0.0095,  0.0100, -0.0074],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0031,  0.0283,  0.0260,  0.0289, -0.0004],\n",
            "        [ 0.0020,  0.0024, -0.0205,  0.0013,  0.0021],\n",
            "        [-0.0818,  0.0027,  0.0003,  0.0113,  0.0076],\n",
            "        [-0.0309,  0.0440, -0.0367, -0.0547,  0.0100],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0656,  0.0336, -0.0258, -0.0189, -0.0053],\n",
            "        [-0.0062,  0.0045, -0.0269,  0.0027,  0.0031],\n",
            "        [-0.0400, -0.0025, -0.0070,  0.0085,  0.0058],\n",
            "        [ 0.0043,  0.0048, -0.0218, -0.0204, -0.0310],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0078,  0.0025, -0.0302, -0.0053,  0.0083],\n",
            "        [-0.0518, -0.0090,  0.0030,  0.0101,  0.0058],\n",
            "        [-0.0095, -0.0224,  0.0054,  0.0033,  0.0025],\n",
            "        [ 0.0279, -0.0030, -0.0042, -0.0279,  0.0011],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0178,  0.0207, -0.0139, -0.0344,  0.0126],\n",
            "        [-0.0400, -0.0097,  0.0255,  0.0197, -0.0098],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0521,  0.0238,  0.0489, -0.0072, -0.0064],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0102, -0.0095, -0.0118,  0.0044,  0.0035],\n",
            "        [-0.0146,  0.0154,  0.0142,  0.0107, -0.0305],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0055,  0.0074, -0.0042,  0.0044,  0.0044],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])\n"
          ]
        }
      ],
      "source": [
        "def forward(self, xb:torch.Tensor) -> torch.Tensor:\n",
        "    return xb @ self.weights + self.bias\n",
        "\n",
        "MNISTLogistic.forward = forward\n",
        "\n",
        "model = MNISTLogistic()\n",
        "print(model(xb)[:4])\n",
        "loss = loss_func(model(xb), yb)\n",
        "loss.backward()\n",
        "print(model.weights.grad[::17, ::2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwMAPcNc04Ei",
        "outputId": "622efeb4-bac4-4bac-b6a7-f1d6574727ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.0131, -0.0375,  0.0346,  ..., -0.0007, -0.0096, -0.0604],\n",
            "        [-0.0717, -0.0018,  0.0351,  ...,  0.0579,  0.0178,  0.0087],\n",
            "        [-0.0325, -0.0509, -0.0461,  ..., -0.0065,  0.0325,  0.0158],\n",
            "        ...,\n",
            "        [ 0.0365,  0.0202,  0.0309,  ..., -0.0218,  0.0219, -0.0927],\n",
            "        [-0.0489,  0.0212,  0.0028,  ..., -0.0283, -0.0154, -0.0650],\n",
            "        [-0.0240, -0.0796, -0.0292,  ...,  0.0144,  0.0453,  0.0060]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "print(*list(model.parameters()), sep=\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "i_R1LK9s0-nC"
      },
      "outputs": [],
      "source": [
        "def fit():\n",
        "    for epoch in range(epochs):\n",
        "        for ii in range((n - 1) // bs + 1):\n",
        "            start_idx = ii * bs \n",
        "            end_idx = start_idx + bs\n",
        "            yb = x_train[start_idx: end_idx]\n",
        "            yb = y_train[start_idx: end_idx]\n",
        "            pred = model(xb)\n",
        "            loss = loss_func(pred, yb)\n",
        "\n",
        "            loss.backward()\n",
        "            with torch.no_grad():\n",
        "                for p in model.parameters():\n",
        "                    p -= p.grad * lr\n",
        "                model.zero_grad()\n",
        "\n",
        "fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLuK5MIx3VWj",
        "outputId": "d1c0a344-7ce9-4986-a5fa-50e6ac53e6b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy comparison -  tensor([0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
            "        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
            "        0., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "tensor(0.8125)\n"
          ]
        }
      ],
      "source": [
        "print(accuracy(model(xb), yb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zFQBx_F3Zuz",
        "outputId": "6d5c86a6-2e5a-461e-e9ee-dab4e2f5c792"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.nn.Modules:\n",
            "\tModule, Identity, Linear, Conv1d, Conv2d, Conv3d, ConvTranspose1d,\n",
            "\tConvTranspose2d, ConvTranspose3d, Threshold, ReLU, Hardtanh, ReLU6,\n",
            "\tSigmoid, Tanh, Softmax, Softmax2d, LogSoftmax, ELU, SELU, CELU, GLU,\n",
            "\tGELU, Hardshrink, LeakyReLU, LogSigmoid, Softplus, Softshrink,\n",
            "\tMultiheadAttention, PReLU, Softsign, Softmin, Tanhshrink, RReLU,\n",
            "\tL1Loss, NLLLoss, KLDivLoss, MSELoss, BCELoss, BCEWithLogitsLoss,\n",
            "\tNLLLoss2d, PoissonNLLLoss, CosineEmbeddingLoss, CTCLoss,\n",
            "\tHingeEmbeddingLoss, MarginRankingLoss, MultiLabelMarginLoss,\n",
            "\tMultiLabelSoftMarginLoss, MultiMarginLoss, SmoothL1Loss,\n",
            "\tGaussianNLLLoss, HuberLoss, SoftMarginLoss, CrossEntropyLoss,\n",
            "\tContainer, Sequential, ModuleList, ModuleDict, ParameterList,\n",
            "\tParameterDict, AvgPool1d, AvgPool2d, AvgPool3d, MaxPool1d, MaxPool2d,\n",
            "\tMaxPool3d, MaxUnpool1d, MaxUnpool2d, MaxUnpool3d, FractionalMaxPool2d,\n",
            "\tFractionalMaxPool3d, LPPool1d, LPPool2d, LocalResponseNorm,\n",
            "\tBatchNorm1d, BatchNorm2d, BatchNorm3d, InstanceNorm1d, InstanceNorm2d,\n",
            "\tInstanceNorm3d, LayerNorm, GroupNorm, SyncBatchNorm, Dropout,\n",
            "\tDropout1d, Dropout2d, Dropout3d, AlphaDropout, FeatureAlphaDropout,\n",
            "\tReflectionPad1d, ReflectionPad2d, ReflectionPad3d, ReplicationPad2d,\n",
            "\tReplicationPad1d, ReplicationPad3d, CrossMapLRN2d, Embedding,\n",
            "\tEmbeddingBag, RNNBase, RNN, LSTM, GRU, RNNCellBase, RNNCell, LSTMCell,\n",
            "\tGRUCell, PixelShuffle, PixelUnshuffle, Upsample, UpsamplingNearest2d,\n",
            "\tUpsamplingBilinear2d, PairwiseDistance, AdaptiveMaxPool1d,\n",
            "\tAdaptiveMaxPool2d, AdaptiveMaxPool3d, AdaptiveAvgPool1d,\n",
            "\tAdaptiveAvgPool2d, AdaptiveAvgPool3d, TripletMarginLoss, ZeroPad2d,\n",
            "\tConstantPad1d, ConstantPad2d, ConstantPad3d, Bilinear,\n",
            "\tCosineSimilarity, Unfold, Fold, AdaptiveLogSoftmaxWithLoss,\n",
            "\tTransformerEncoder, TransformerDecoder, TransformerEncoderLayer,\n",
            "\tTransformerDecoderLayer, Transformer, LazyLinear, LazyConv1d,\n",
            "\tLazyConv2d, LazyConv3d, LazyConvTranspose1d, LazyConvTranspose2d,\n",
            "\tLazyConvTranspose3d, LazyBatchNorm1d, LazyBatchNorm2d,\n",
            "\tLazyBatchNorm3d, LazyInstanceNorm1d, LazyInstanceNorm2d,\n",
            "\tLazyInstanceNorm3d, Flatten, Unflatten, Hardsigmoid, Hardswish, SiLU,\n",
            "\tMish, TripletMarginWithDistanceLoss, ChannelShuffle\n"
          ]
        }
      ],
      "source": [
        "import textwrap \n",
        "\n",
        "print(\"torch.nn.Modules:\", *textwrap.wrap(\", \".join(torch.nn.modules.__all__)), sep=\"\\n\\t\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "j6e9W6SY37ZQ"
      },
      "outputs": [],
      "source": [
        "class MNISTLogistic(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__() \n",
        "        self.lin = nn.Linear(784, 10)\n",
        "\n",
        "    def forward(self, xb):\n",
        "        return self.lin(xb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6KYltO54bkp",
        "outputId": "c2d93413-8e30-443c-aebd-e63f6de145a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.3073, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "model = MNISTLogistic()\n",
        "print(loss_func(model(xb), yb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DZArNjU4gJu",
        "outputId": "06c6d9d1-869e-4b5d-963b-ec767a01214b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear(in_features=784, out_features=10, bias=True)\n"
          ]
        }
      ],
      "source": [
        "print(*list(model.children()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPmtrPge4oKR",
        "outputId": "5a14b79d-af99-4cd1-8eba-02a9ac340928"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.0244, -0.0078,  0.0233,  ...,  0.0039,  0.0260, -0.0055],\n",
            "        [-0.0046, -0.0072,  0.0091,  ..., -0.0174,  0.0290, -0.0111],\n",
            "        [-0.0271, -0.0218, -0.0245,  ...,  0.0295, -0.0101,  0.0011],\n",
            "        ...,\n",
            "        [ 0.0275,  0.0072, -0.0120,  ...,  0.0153, -0.0182,  0.0048],\n",
            "        [ 0.0167,  0.0322,  0.0059,  ..., -0.0221, -0.0267, -0.0319],\n",
            "        [-0.0107, -0.0088,  0.0277,  ...,  0.0231, -0.0083, -0.0141]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.0131, -0.0102, -0.0111,  0.0134,  0.0346,  0.0006,  0.0306, -0.0313,\n",
            "         0.0172,  0.0356], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "print(*list(model.parameters()), sep=\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhOdNQpd498I"
      },
      "source": [
        "### Applying gradients with `torch.optim.Optimizer`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "swfe5vMo4wAR"
      },
      "outputs": [],
      "source": [
        "from torch import optim \n",
        "\n",
        "def configure_optimizer(model: nn.Module) -> optim.Optimizer:\n",
        "    return optim.Adam(model.parameters(), lr=3e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yy1iz3lP5JPv",
        "outputId": "5ed29bd7-3e36-423c-e7a2-e5cfa66eef69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "after training: \n",
            "\ttensor(2.3011, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "model = MNISTLogistic()\n",
        "opt = configure_optimizer(model)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for ii in range((n - 1) // bs + 1):\n",
        "        start_idx = ii * bs \n",
        "        end_idx = start_idx + bs \n",
        "        xb = x_train[start_idx: end_idx]\n",
        "        yb = y_train[start_idx: end_idx]\n",
        "        pred = model(xb)\n",
        "        loss = loss_func(pred, yb)\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "print(\"after training: \", loss_func(model(xb), yb), sep=\"\\n\\t\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "JuFz4I9C57m2"
      },
      "outputs": [],
      "source": [
        "from text_recognizer.data.util import BaseDataset \n",
        "\n",
        "train_ds = BaseDataset(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "RxU07D_16XgV"
      },
      "outputs": [],
      "source": [
        "BaseDataset??"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4JC_iYW6cxu",
        "outputId": "b03df77a-d47c-497a-a14c-f32888685403"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.2878, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "model = MNISTLogistic()\n",
        "opt = configure_optimizer(model)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for ii in range((n - 1) // bs + 1):\n",
        "        xb, yb = train_ds[ii * bs: ii * bs + bs]\n",
        "        pred = model(xb)\n",
        "        loss = loss_func(pred, yb)\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "print(loss_func(model(xb), yb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvGAcfff7xaH"
      },
      "source": [
        "### Batching up data with `torch.utils.data.DataLoader`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "QghcUL-i7X9N"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_ds = BaseDataset(x_train, y_train)\n",
        "train_dataloader = DataLoader(train_ds, batch_size = bs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "niyoCQfJ8tZD"
      },
      "outputs": [],
      "source": [
        "def fit(self: nn.Module, train_dataloader: DataLoader):\n",
        "    opt = configure_optimizer(self)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for xb, yb in train_dataloader:\n",
        "            pred = self(xb)\n",
        "            loss = loss_func(pred, yb)\n",
        "\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "\n",
        "MNISTLogistic.fit = fit "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOP-UMjF9Icv",
        "outputId": "5214ba35-ba71-4255-f233-55e1a65d85e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.3974, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "model = MNISTLogistic()\n",
        "\n",
        "model.fit(train_dataloader)\n",
        "\n",
        "print(loss_func(model(xb), yb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmtjOL8c9kPI"
      },
      "source": [
        "### Swapping in another model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "oTkJm04-9N4C"
      },
      "outputs": [],
      "source": [
        "from text_recognizer.models.mlp import MLP \n",
        "\n",
        "MLP.fit = fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "TKZIgb2j9sAw"
      },
      "outputs": [],
      "source": [
        "MLP.forward??"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "WYes99sN9tJ5"
      },
      "outputs": [],
      "source": [
        "MLP.__init__??"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "eNMhAjqZ-6Sf"
      },
      "outputs": [],
      "source": [
        "MLP?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXwLYhzd92ft",
        "outputId": "537dbb22-deeb-43b9-fa3d-c670020ced1f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_dims': (784,),\n",
              " 'mapping': {0: '0',\n",
              "  1: '1',\n",
              "  2: '2',\n",
              "  3: '3',\n",
              "  4: '4',\n",
              "  5: '5',\n",
              "  6: '6',\n",
              "  7: '7',\n",
              "  8: '8',\n",
              "  9: '9'}}"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "digits_to_9 = list(range(10))\n",
        "data_config = {\"input_dims\": (784,), \"mapping\": {digit: str(digit) for digit in digits_to_9}}\n",
        "data_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vp7RioNO-gDp",
        "outputId": "816bc4f4-2136-415e-b789-81b3899cd5b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (fc1): Linear(in_features=784, out_features=1024, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (fc2): Linear(in_features=1024, out_features=128, bias=True)\n",
              "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = MLP(data_config)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZZCVueE-i-0",
        "outputId": "adb9a031-5dac-4649-8bad-bcb1ed7174d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.0114, -0.0035,  0.0036,  ..., -0.0055, -0.0151,  0.0256],\n",
              "        [-0.0276,  0.0085,  0.0221,  ...,  0.0091,  0.0206, -0.0302],\n",
              "        [ 0.0059, -0.0135,  0.0255,  ...,  0.0336, -0.0219,  0.0240],\n",
              "        ...,\n",
              "        [ 0.0311, -0.0077, -0.0144,  ..., -0.0324,  0.0316, -0.0280],\n",
              "        [-0.0300,  0.0034, -0.0024,  ...,  0.0304,  0.0138, -0.0331],\n",
              "        [-0.0273, -0.0180,  0.0299,  ...,  0.0354,  0.0094,  0.0227]],\n",
              "       requires_grad=True)"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fc1.weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKQJq79q_DHX",
        "outputId": "3ffbcde5-6757-48f4-a490-4436bb3f7218"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "before training:  tensor(2.2985, grad_fn=<NllLossBackward0>)\n",
            "after training:  tensor(0.1131, grad_fn=<NllLossBackward0>)\n",
            "CPU times: user 20.1 s, sys: 244 ms, total: 20.3 s\n",
            "Wall time: 21.7 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "print(\"before training: \", loss_func(model(xb), yb))\n",
        "\n",
        "train_ds = BaseDataset(x_train, y_train)\n",
        "train_dataloader = DataLoader(train_ds, batch_size=bs)\n",
        "fit(model, train_dataloader)\n",
        "\n",
        "print(\"after training: \", loss_func(model(xb), yb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GphNFBEYA0zM"
      },
      "source": [
        "## Extra goodies: data organization, validation, and acceleration\n",
        "\n",
        "\n",
        "### Making the GPU go brrrr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RExnDOHM_SpY",
        "outputId": "3b97734c-1f2d-495c-c511-9adaafd85257"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fri Aug 26 00:52:53 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8     9W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    !nvidia-smi\n",
        "else:\n",
        "    print(\":(\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0h8-DMNQBM1I",
        "outputId": "8a48cc84-e07d-4e83-a273-73cc1bb694e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "loss_func(model(xb.to(device)), yb.to(device))\n",
        "\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "tZ55Oz0XKnGV"
      },
      "outputs": [],
      "source": [
        "def push_to_device(tensor):\n",
        "    return tensor.to(device)\n",
        "\n",
        "train_ds = BaseDataset(x_train, y_train, transform=push_to_device, target_transform=push_to_device)\n",
        "\n",
        "train_dataloader = DataLoader(train_ds, batch_size=bs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAr6Vn7KLHXH"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CFF5l2BMM7A",
        "outputId": "694ff0fb-541c-421e-e560-b4692d216beb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0 cuda:0\n"
          ]
        }
      ],
      "source": [
        "for xb, yb in train_dataloader:\n",
        "    print(xb.device, yb.device)\n",
        "    break;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVPXGY-MK905",
        "outputId": "ae9c0901-e9e1-41e0-a80d-edc028a78cf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.1047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "CPU times: user 6.55 s, sys: 112 ms, total: 6.66 s\n",
            "Wall time: 6.76 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "model = MLP(data_config)\n",
        "model.to(device)\n",
        "\n",
        "model.fit(train_dataloader)\n",
        "\n",
        "print(loss_func(model(push_to_device(xb)), push_to_device(yb)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PO8dg2vTQa9Z"
      },
      "source": [
        "## Adding validation data and organizing data code with `DataModule`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "tW1y03ZGLcm9"
      },
      "outputs": [],
      "source": [
        "class MNISTDataModule:\n",
        "    url = \"https://github.com/pytorch/tutorials/raw/master/_static/\"\n",
        "    filename = \"mnist.pkl.gz\"\n",
        "\n",
        "    def __init__(self, dir, bs=32):\n",
        "        self.dir = dir\n",
        "        self.bs = bs\n",
        "        self.path = self.dir / self.filename\n",
        "\n",
        "    def prepare_data(self):\n",
        "        if not (self.path).exists():\n",
        "            content = requests.get(self.url + self.filename).content\n",
        "            self.path.open(\"wb\").write(content)\n",
        "\n",
        "    def setup(self):\n",
        "        with gzip.open(self.path, \"rb\") as f:\n",
        "            ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")\n",
        "\n",
        "        x_train, y_train, x_valid, y_valid = map(\n",
        "            torch.Tensor, (x_train, y_train, x_valid, y_valid)\n",
        "        )\n",
        "        # print(y_train[0], y_train[0].type)\n",
        "        # print(y_valid[0], y_valid[0].type)\n",
        "\n",
        "        self.train_ds = BaseDataset(x_train, y_train, transform=push_to_device, target_transform=push_to_device)\n",
        "        self.valid_ds = BaseDataset(x_valid, y_valid, transform=push_to_device, target_transform=push_to_device)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return torch.utils.data.DataLoader(self.train_ds, batch_size=self.bs, shuffle=True)\n",
        "\n",
        "    def valid_dataloader(self):\n",
        "        return torch.utils.data.DataLoader(self.valid_ds, batch_size=self.bs, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "wvuojgmInPFh"
      },
      "outputs": [],
      "source": [
        "def fit(self: nn.Module, datamodule):\n",
        "    datamodule.prepare_data()\n",
        "    datamodule.setup()\n",
        "\n",
        "    val_dataloader = datamodule.valid_dataloader()\n",
        "\n",
        "    self.eval()\n",
        "    with torch.no_grad():\n",
        "        valid_loss = sum(loss_func(self(xb), yb.type(torch.LongTensor).to(device)) for xb, yb in val_dataloader)\n",
        "\n",
        "    print(\"before start of training: \", valid_loss / len(val_dataloader))\n",
        "\n",
        "    opt = configure_optimizer(self)\n",
        "    train_dataloader = datamodule.train_dataloader()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        self.train()\n",
        "\n",
        "        for xb, yb in train_dataloader:\n",
        "            pred = self(xb)\n",
        "            loss = loss_func(pred, yb.type(torch.LongTensor).to(device))\n",
        "\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            valid_loss = sum(loss_func(self(xb), yb.type(torch.LongTensor).to(device)) for xb, yb in val_dataloader)\n",
        "        print(epoch, valid_loss / len(val_dataloader))\n",
        "\n",
        "MNISTLogistic.fit = fit\n",
        "MLP.fit = fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTXRis5xoVE5",
        "outputId": "ca2bb7dc-75dc-4c4b-c34e-be56b58d1905"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "before start of training:  tensor(2.3064, device='cuda:0')\n",
            "0 tensor(0.1637, device='cuda:0')\n",
            "1 tensor(0.1130, device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "model = MLP(data_config)\n",
        "model.to(device)\n",
        "\n",
        "datamodule = MNISTDataModule(dir=path, bs=32)\n",
        "\n",
        "model.fit(datamodule=datamodule)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJ2PRgntuTks"
      },
      "source": [
        "### try out different hyperparameters for the `MLP` and for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "hNBZgbOsolUg"
      },
      "outputs": [],
      "source": [
        "MLP.__init__??"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8PtRoCYuZfD",
        "outputId": "0b7426ff-c839-4650-b696-9fba786189a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "before start of training:  tensor(2.3041, device='cuda:0')\n",
            "0 tensor(0.2283, device='cuda:0')\n",
            "1 tensor(0.1610, device='cuda:0')\n",
            "2 tensor(0.1271, device='cuda:0')\n",
            "3 tensor(0.1105, device='cuda:0')\n",
            "4 tensor(0.0971, device='cuda:0')\n",
            "5 tensor(0.0872, device='cuda:0')\n",
            "6 tensor(0.0801, device='cuda:0')\n",
            "7 tensor(0.0790, device='cuda:0')\n",
            "CPU times: user 23.8 s, sys: 255 ms, total: 24 s\n",
            "Wall time: 24 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "from argparse import Namespace \n",
        "\n",
        "args = Namespace(epochs=2, bs=32) \n",
        "\n",
        "epochs = 8\n",
        "bs = 128 \n",
        "\n",
        "def configure_optimizer(model: nn.Module) -> optim.Optimizer:\n",
        "    return optim.Adam(model.parameters(), lr=3e-4)\n",
        "\n",
        "model = MLP(data_config, args=args)\n",
        "model.to(device)\n",
        "\n",
        "datamodule = MNISTDataModule(dir=path, bs=bs)\n",
        "\n",
        "model.fit(datamodule=datamodule)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qs6Emt9u5Op",
        "outputId": "903938a5-81ca-4db8-809c-5335dadb2f7e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.9770, device='cuda:0')"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_dataloader = datamodule.valid_dataloader()\n",
        "valid_acc = sum(accuracy(model(xb), yb) for xb, yb in val_dataloader) / len(val_dataloader)\n",
        "valid_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kL0M7S5vlQS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMORCUalsTUEsPd0NBmaxiC",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "c_lab01_pytorch.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "7f9348cf459ed725a61e8ad1c80faeaacb2142bde10389f69ecee96b2c244d0d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
