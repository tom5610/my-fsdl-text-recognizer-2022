{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 02a: PyTorch Lightning\n",
    "\n",
    "## What You Will Learn\n",
    "\n",
    "* The core components of a PyTorch Lightning training loop: `LightningModule`s and `Trainer`s\n",
    "* Useful quality-of-life improvements offered by PyTorch Lightning: `LightningDataModule`s, `Callback`s, and `Metric`s\n",
    "* How we use these features in the FSDL codebase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tomlu/Workspace\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/tomlu/Workspace/my-fsdl-text-recognizer-2022/lab02')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "current_dir = Path.cwd()\n",
    "\n",
    "print(current_dir)\n",
    "\n",
    "lab_idx = 2\n",
    "lab_name = f\"lab{str(lab_idx).zfill(2)}\"\n",
    "my_fsdl = \"my-fsdl-text-recognizer-2022\"\n",
    "\n",
    "if current_dir.name == lab_name:\n",
    "    pass \n",
    "else:\n",
    "    os.chdir(f\"{current_dir}/{my_fsdl}/{lab_name}\")\n",
    "\n",
    "Path.cwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Lightning\n",
    "\n",
    "PyTorch is a powerful library for executing differentiable tensor operations with hardware acceleration and it includes many neural network primitives, but it has no concept of \"training\". At a high level, an `nn.Module` is stateful function with gradients and a `torch.optim.Optimizer` can update that state using gradients, but there's no pre-built tools in PyTorch to iteratively generate those gradients from data.\n",
    "\n",
    "So the first thing many folks do in PyTorch is write that code -- a \"training loop\" to iterate over their `DataLoader`, which in pseudocode might look something like:\n",
    "\n",
    "```Python\n",
    "for batch in dataloader:\n",
    "    inputs, targets = batch\n",
    "\n",
    "    outputs = model(inputs)\n",
    "    loss = some_loss_function(inputs, outputs)\n",
    "\n",
    "    optimizer.zero_gradients()\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "```\n",
    "\n",
    "This is a solid start, but other needs immediately arise. You'll want to run your model on validation and test data, which need their own `DataLoader`s. Once finished, you'll want to save your model -- and for long-running jobs, you probably want to save checkpoints of the train process so that it can be resumed in case of a crash. For state-of-the-art model performance in many domains, you'll want to distribute your training across multiple nodes/machines and across multiple GPUs within those nodes.\n",
    "\n",
    "PyTorch Lightning is a popular framework on top of PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://pytorch-lightning.readthedocs.io/en/0.8.5/'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "version = pl.__version__\n",
    "\n",
    "docs_url = f\"https://pytorch-lightning.readthedocs.io/en/{version}/\"\n",
    "docs_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At its core, PyTorch Lightning provides\n",
    "1. the `pl.Trainer` class, which organizes and executes your training, validation, and test loops, and\n",
    "2. the `pl.LightningModule` class, which links optimizers to models and definies how the model behaves during training, validation, and testing.\n",
    "\n",
    "Before these are kitted out with all the features a cutting-edge deep learning code needs:\n",
    "* flags for switching device types and distributed computing strategy\n",
    "* saving, checkpointing, and resumption\n",
    "* calculation and logging of metrics\n",
    "\n",
    "and much more.\n",
    "\n",
    "Importantly these features can be easily added, removed, extended, or bypassed as desired, meaning your code isn't constrained by the framework. \n",
    "\n",
    "In some ways, you can think of Lighning as a tool for \"organizing\" your PyTorch code, as shown in the video below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"720\"\n",
       "            height=\"720\"\n",
       "            src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/pl_docs/pl_mod_vid.m4v\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x15f543f10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython.display as display\n",
    "\n",
    "\n",
    "display.IFrame(src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/pl_docs/pl_mod_vid.m4v\",\n",
    "               width=720, height=720)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's opposed to the other way frameworks are designed, to provide abstractions over the lower-lvel library (here, PyTorch).\n",
    "\n",
    "Because of this \"organize don't abstract\" style, writing PyTorch Lightning code involves a lot of over-riding of methods -- you inherit from a class and then implement the specific version of a general method that you need for your code, rather than lightning providing a bunch of already fully-defined classes that you just instantiate, using arguments for configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
