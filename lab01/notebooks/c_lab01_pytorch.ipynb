{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "c_lab01_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNI9XtK/a97+3GfVkoqfH3R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tom5610/my-fsdl-text-recognizer-2022/blob/main/lab01/notebooks/c_lab01_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lab 01: Deep Neural Networks in PyTorch\n",
        "\n",
        "Objective:\n",
        "* how to write a basic neural network from scatch in PyTorch\n",
        "* How the submodules of torch, like `torch.nn` and `torch.utils.data`, make writing performant neural network training and inference code easier"
      ],
      "metadata": {
        "id": "SKfcRGYnyOxY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "Below cell will run full environment setup in colab."
      ],
      "metadata": {
        "id": "yRH_STeCygfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lab_idx = 1\n",
        "\n",
        "if 'bootstrap' not in locals() or bootstrap.run:\n",
        "    pythonpath, = !echo $PYTHONPATH\n",
        "    if '.' not in pythonpath.split(':'):\n",
        "        pythonpath = \".:\" + pythonpath\n",
        "        %env PYTHONPATH={pythonpath}\n",
        "        !echo $PYTHONPATH\n",
        "\n",
        "    # get both Colab and local notebooks into the same state\n",
        "    !wget --quiet https://fsdl.me/gist-bootstrap -O bootstrap.py\n",
        "    import bootstrap\n",
        "\n",
        "    bootstrap.change_to_lab_dir(lab_idx=lab_idx)\n",
        "\n",
        "    # allow 'hot-reloading' of modules\n",
        "    %load_ext autoreload\n",
        "    %autoreload 2\n",
        "    # needed for inline plots in some contexts\n",
        "    %matplotlib inline\n",
        "\n",
        "    bootstrap.run = False\n",
        "\n",
        "!pwd\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNzmJtFVye94",
        "outputId": "35d5af93-2c74-41aa-db8e-9a96af7f3121"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTHONPATH=.:/env/python\n",
            ".:/env/python\n",
            "/content/fsdl-text-recognizer-2022-labs/lab01\n",
            "\u001b[0m\u001b[01;34mnotebooks\u001b[0m/  \u001b[01;34mtext_recognizer\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting data and making Tensors\n",
        "\n",
        "before we can build a model, we need data. \n",
        "\n",
        "Use MNIST dataset of handwritten digits.\n",
        "\n",
        "The data used to train state-of-the-art models these days is generally too large to be stored on the disk of any single machine (to say nothing of the RAM!), so fetching data over a network is a common first step in model training."
      ],
      "metadata": {
        "id": "ACyi8BTcz1nk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path \n",
        "import requests\n",
        "\n",
        "def download_mnist(path):\n",
        "    url = \"https://github.com/pytorch/tutorials/raw/master/_static/\"\n",
        "    filename = \"mnist.pkl.gz\"\n",
        "\n",
        "    if not (path / filename).exists():\n",
        "        content = requests.get(url + filename).content\n",
        "        (path / filename).open(\"wb\").write(content)\n",
        "\n",
        "    return path / filename\n",
        "\n",
        "data_path = Path(\"data\") if Path(\"data\").exists() else Path(\"../data\")\n",
        "path = data_path / \"downloaded\" / \"vector-mnist\"\n",
        "path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "datafile = download_mnist(path)"
      ],
      "metadata": {
        "id": "iXAz4GGHzhy0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gzip\n",
        "import pickle \n",
        "\n",
        "def read_mnist(path):\n",
        "    with gzip.open(path, \"rb\") as f:\n",
        "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")\n",
        "    return x_train, y_train, x_valid, y_valid\n",
        "\n",
        "x_train, y_train, x_valid, y_valid = read_mnist(datafile)\n",
        "    "
      ],
      "metadata": {
        "id": "IUZckCJG39Nn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "\n",
        "x_train, y_train, x_valid, y_valid = map(\n",
        "    torch.tensor, (x_train, y_train, x_valid, y_valid)\n",
        ")"
      ],
      "metadata": {
        "id": "c_qrmLb14ZHk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train, y_train, sep=\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJa0EXhb4ywJ",
        "outputId": "129e244a-19fa-454f-a999-6f4a9a75cb13"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
            "tensor([5, 0, 4,  ..., 8, 4, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[0], x_train[0, ::2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbrD0gYi5eP6",
        "outputId": "bd7e0686-cfe0-4699-c9e1-fa3cd4781a62"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(5),\n",
              " tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0117, 0.0703, 0.4922, 0.6836, 0.6484,\n",
              "         0.9648, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1172, 0.3672,\n",
              "         0.6641, 0.9883, 0.9883, 0.8789, 0.9883, 0.7617, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.9297, 0.9883, 0.9883, 0.9883, 0.9883, 0.3633,\n",
              "         0.3203, 0.1523, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8555,\n",
              "         0.9883, 0.9883, 0.7734, 0.9648, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.3125, 0.4180, 0.9883, 0.0430, 0.1680,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0039, 0.9883, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9883, 0.0078,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.7422, 0.2734, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1367,\n",
              "         0.8789, 0.4219, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9375, 0.9883, 0.0977, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.1758, 0.9883, 0.5859, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3633, 0.9883,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.9883, 0.2500, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1797, 0.7148,\n",
              "         0.9883, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.1523, 0.8945, 0.9883, 0.9766, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0938, 0.8633, 0.9883,\n",
              "         0.9883, 0.3047, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0898, 0.8320, 0.9883, 0.9883, 0.3164, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0703, 0.8555, 0.9883, 0.9883,\n",
              "         0.3125, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.2148, 0.8828, 0.9883, 0.9883, 0.5195, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5312, 0.9883, 0.8281, 0.5156,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000]))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.ndim, y_train.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARnhmks_5muZ",
        "outputId": "bf4146d6-9c18-4140-ada3-3078d457a97d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n, c = x_train.shape\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inzqGjFF6Hj_",
        "outputId": "e434d1fb-c134-4373-d3d1-476a47f33831"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([50000, 784])\n",
            "torch.Size([50000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random \n",
        "\n",
        "import wandb \n",
        "\n",
        "import text_recognizer.metadata.mnist as metadata\n",
        "\n",
        "idx = random.randint(0, len(x_train))\n",
        "example = x_train[idx]\n",
        "\n",
        "print(y_train[idx])\n",
        "wandb.Image(example.reshape(*metadata.DIMS)).image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "id": "YGPKHIer6QvQ",
        "outputId": "3d70b2ce-91bf-431a-c7d2-c6ec5a68a3e8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=28x28 at 0x7FEAAB1DE050>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAApklEQVR4nO3RIQ7EIBCF4QfBYNoEwQXAcZlKuFKP0rOg0Bh6gFocrNhULySTbHbTXw9fMgzw9K2O40gpKaVGhvkg2nt3zoUQKNF33nsyVEpprQVwXRcZWmvNOQMwxpChANgdJdrvKNGpJtanRwcXn0MZY5xz+kO11ogP9Tt/OtX/HSrGCEAIsa7r4JPPaa3P82ytlVKWZSFzt21LKe37LoQgQ58GewHDM0Ttje/uewAAAABJRU5ErkJggg==\n"
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build a DNN using only `torch.Tensor` methods and Python\n",
        "\n",
        "### Defining the model"
      ],
      "metadata": {
        "id": "4u1hTNXg9X8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "weights = torch.randn(784, 10) / math.sqrt(784)\n",
        "weights.requires_grad_()\n",
        "bias = torch.zeros(10, requires_grad=True)"
      ],
      "metadata": {
        "id": "9W3QEa8K7HP8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights.ndim, weights.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKWAt2Nd-GFY",
        "outputId": "797e3311-3488-44c0-e4c3-53147e53288a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, torch.Size([784, 10]))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def linear(x: torch.Tensor) -> torch.Tensor:\n",
        "    return x @ weights + bias"
      ],
      "metadata": {
        "id": "Mv6Lapqy-PRF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 3\n",
        "a = torch.rand(n)\n",
        "b = torch.rand(n)\n",
        "print(torch.matmul(a, b))\n",
        "print(a @ b)\n",
        "a, b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWlrvcUtgFOz",
        "outputId": "a0754b84-f4eb-4e28-affd-0511e6657690"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.5357)\n",
            "tensor(0.5357)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.8534, 0.0395, 0.1505]), tensor([0.5625, 0.8993, 0.1341]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "0.5367 * 0.0799 + 0.361 * 0.3948 + 0.3556 * 0.6106"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V91HqSTsgTvd",
        "outputId": "4c03c6df-a276-4d07-d119-7bc6327ae646"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.40253448999999997"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.rand((3, 2))\n",
        "b = torch.rand((2, 2))\n",
        "result = a.mm(b)"
      ],
      "metadata": {
        "id": "xnit7vxEht4g"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a, b, result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIRk3B8rh8Ob",
        "outputId": "11dee55d-829a-4744-a602-d239af9592eb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.1425, 0.8541],\n",
              "         [0.2732, 0.6872],\n",
              "         [0.6426, 0.2616]]), tensor([[0.6202, 0.0251],\n",
              "         [0.3230, 0.1609]]), tensor([[0.3642, 0.1410],\n",
              "         [0.3914, 0.1174],\n",
              "         [0.4830, 0.0582]]))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def log_softmax(x: torch.Tensor) -> torch.Tensor:\n",
        "    return x - torch.log(torch.sum(torch.exp(x), axis = 1))[:, None]\n",
        "\n",
        "def model(xb: torch.Tensor) -> torch.Tensor:\n",
        "    return log_softmax(linear(xb))"
      ],
      "metadata": {
        "id": "jGQapurliM8t"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bs = 64 # batch size\n",
        "\n",
        "xb = x_train[0: bs] # a batch of inputs\n",
        "outs = model(xb)\n",
        "\n",
        "print(outs[0], outs.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YON-Yat8wQfs",
        "outputId": "a6665d6f-5a0b-434c-c5a6-f5aed1be2a1a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-2.3745, -3.1393, -2.3581, -2.2854, -2.1499, -3.1087, -2.3167, -2.1020,\n",
            "        -1.6897, -2.2952], grad_fn=<SelectBackward0>) torch.Size([64, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining the loss and metrics"
      ],
      "metadata": {
        "id": "32dBTixvxBJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(out: torch.Tensor, yb: torch.Tensor) -> torch.Tensor:\n",
        "    preds = torch.argmax(out, dim=1)\n",
        "    print('accuracy comparison - ', (preds == yb).float())\n",
        "    return (preds == yb).float().mean()"
      ],
      "metadata": {
        "id": "X95ORSKUwjOI"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yb = y_train[0: bs]\n",
        "\n",
        "acc = accuracy(outs, yb)\n",
        "\n",
        "print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bSqnMiVxST8",
        "outputId": "2017cb53-cbb5-444a-a73e-1b34edd533ce"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy comparison -  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "tensor(0.0938)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy(output: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
        "    return -output[range(target.shape[0]), target].mean()\n",
        "\n",
        "loss_func = cross_entropy"
      ],
      "metadata": {
        "id": "bv4w1lzTxXsl"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(loss_func(outs, yb), -torch.log(torch.tensor(1 / 10)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d5O5Xzwz9ZN",
        "outputId": "ab29bf9b-9f46-4128-d44b-1980cc5dd16d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.4199, grad_fn=<NegBackward0>) tensor(2.3026)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.log(torch.tensor(1 / 10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlUw1Xs60Byd",
        "outputId": "c32cdfbb-10ff-4532-8ec3-525ebd0a13d7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-2.3026)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = loss_func(outs, yb)\n",
        "\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "u2Hsq9960HKZ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights.grad, bias.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeBo3jhF0bLA",
        "outputId": "c8650a47-0bbb-4b61-9f44-567bdb2b03df"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
              " tensor([ 0.0012, -0.0519,  0.0194, -0.0198, -0.0352,  0.0182, -0.0047,  0.0488,\n",
              "          0.0525, -0.0286]))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining and running the fitting loop\n",
        "\n",
        "We now have all the ingredients we need to fit a neural network to data:\n",
        "\n",
        "* data (x_train, y_train)\n",
        "* a network architecture with parameters (model, weights, and bias)\n",
        "* a loss_func to optimize (cross_entropy) that supports .backward computation of gradients"
      ],
      "metadata": {
        "id": "ALffB6Yt0zaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.5\n",
        "epochs = 2\n",
        "\n",
        "for epoch in range(epochs): # loop over the data repeatedly\n",
        "    for ii in range((n - 1) // bs + 1):\n",
        "        start_idx = ii * bs\n",
        "        end_idx = start_idx + bs\n",
        "\n",
        "        # pull batches from x and from y\n",
        "        xb = x_train[start_idx:end_idx]\n",
        "        yb = y_train[start_idx:end_idx]\n",
        "\n",
        "        # run model\n",
        "        pred = model(xb)\n",
        "\n",
        "        # get loss\n",
        "        loss = loss_func(pred, yb)\n",
        "\n",
        "        # calculate the gradients with a backwards pass\n",
        "        loss.backward()\n",
        "\n",
        "        # update the parameters\n",
        "        with torch.no_grad(): # we don't want to track gradients through this part!\n",
        "            # SGD learning rule: update with negative gradient scaled by lr\n",
        "            weights -= weights.grad * lr\n",
        "            bias -= bias.grad * lr\n",
        "\n",
        "            # achtung: PyTorch doesn't assume you're done with gradients\n",
        "            #.         until you say so -- by explicitly \"deleting\" them. i.e. setting the gradients to 0.\n",
        "            weights.grad.zero_()\n",
        "            bias.grad.zero_()\n"
      ],
      "metadata": {
        "id": "z7XzK1Io0iTo"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-LYqR5M2bld",
        "outputId": "3e845e29-9f4c-4570-9d75-276b605a912d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy comparison -  tensor([0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
            "        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "tensor(1.0131, grad_fn=<NegBackward0>) tensor(0.8281)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx = random.randint(0, len(x_train))\n",
        "example = x_train[idx: idx+1]\n",
        "\n",
        "out = model(example)\n",
        "\n",
        "print(out.argmax())\n",
        "wandb.Image(example.reshape(28, 28)).image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "id": "n28GLemQ27aX",
        "outputId": "693a0832-2ecc-4d09-cebc-0a0ab98b5698"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=28x28 at 0x7FEAAB12E390>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAABSUlEQVR4nO2UscqCUBSAz702OAi1WASt4lJLIAZNgosvEPQCPYGLD+FTtLaEENSa092EiNZwEQdbBBXi3H9o+fmhvNFdfuhbz+HjO3e4AF++PIcQMpvNTqcT5zzP88lkIkE6nU4RMUkS13XzPN9ut58aKaXH4zHLMk3TAGC9XotI6euxoijz+Xy325VlCQBFUYikdF6POedFUXie5/v+cDhcLBaMsU9L7/e7aZr7/d5xHNu2B4NBv98nhIj0CkEpTdMUETudlvtaSv9IZTY+sCwLEeM4blW/UbparQDgcDhwzj+q+835fEbEXq8nzWgYRtM0cRxT+sZxLYRhiIjL5VKaEQAYY4g4Go2kGXVdv91ul8tFVVWRfaEHGo/H3W43iqK6rqVJH3/oZrMRWRaVuq5bVVWWZTKlmqYxxq7Xq0wpAARBILj5r/gBcsB9jQlSBv8AAAAASUVORK5CYII=\n"
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Refactoring with core `torch.nn` components\n",
        "\n",
        "\n",
        "### Using `torch.nn.functional` for stateless computation"
      ],
      "metadata": {
        "id": "we4djKmg5ekB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "loss_func = F.cross_entropy\n",
        "\n",
        "def model(xb):\n",
        "    return xb @ weights + bias"
      ],
      "metadata": {
        "id": "xJEDeN623W5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBH72ULw52pw",
        "outputId": "e97ca9d8-2e78-48a0-d457-42ba894934cf"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy comparison -  tensor([0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
            "        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "tensor(1.0131, grad_fn=<NegBackward0>) tensor(0.8281)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using torch.nn.Module to define functions whose state is given by `torch.nn"
      ],
      "metadata": {
        "id": "_k238jB96JLI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "class MNISTLogistic(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__() # this is mandatory as nn.Module does import setup\n",
        "        self.weights = nn.Parameter(torch.randn(784, 10) / math.sqrt(784))\n",
        "        self.bias = nn.Parameter(torch.zeros(10))"
      ],
      "metadata": {
        "id": "PyklJuFL5-jG"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(self, xb:torch.Tensor) -> torch.Tensor:\n",
        "    return xb @ self.weights + self.bias\n",
        "\n",
        "MNISTLogistic.forward = forward\n",
        "\n",
        "model = MNISTLogistic()\n",
        "print(model(xb)[:4])\n",
        "loss = loss_func(model(xb), yb)\n",
        "loss.backward()\n",
        "print(model.weights.grad[::17, ::2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHgDmZiI03t7",
        "outputId": "b8a3c9f3-0d6d-412c-d752-04b8bf05902e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-2.7356e-01, -6.1284e-01, -4.4267e-01,  1.0994e-01,  1.6760e-01,\n",
            "          1.8876e-01,  1.8824e-01,  7.0798e-02, -2.7284e-01,  6.4952e-01],\n",
            "        [-2.7472e-01,  1.8758e-01, -7.9060e-01,  6.3794e-01, -3.8115e-01,\n",
            "          5.8444e-02,  2.4837e-01, -1.2672e-01, -1.3872e-01,  2.7652e-01],\n",
            "        [-3.7612e-01, -2.5516e-01, -5.4322e-01, -1.3624e-01,  3.7994e-01,\n",
            "         -1.1055e-01,  6.5418e-01,  4.4629e-01, -4.0257e-01,  9.3307e-02],\n",
            "        [-5.4124e-04, -3.2731e-01,  3.7658e-02,  2.3763e-02, -1.6391e-03,\n",
            "          1.6479e-01, -5.0025e-01, -8.9057e-03, -5.8572e-01, -1.0472e-01]],\n",
            "       grad_fn=<SliceBackward0>)\n",
            "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000, -0.0288,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0162, -0.0345,  0.0000, -0.0396, -0.0118],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0801, -0.0279, -0.0519, -0.0134, -0.0371],\n",
            "        [ 0.0000, -0.0309, -0.0287,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.1066, -0.0308, -0.0032, -0.0497, -0.0700],\n",
            "        [ 0.0000,  0.0000, -0.0060,  0.0000,  0.0000],\n",
            "        [-0.1082, -0.0345, -0.0549,  0.0000, -0.0547],\n",
            "        [-0.0471, -0.0117, -0.0326, -0.0048, -0.0192],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0417, -0.0109, -0.0095,  0.0000, -0.0223],\n",
            "        [ 0.0000,  0.0000, -0.0227,  0.0000,  0.0000],\n",
            "        [-0.0988, -0.0154, -0.0164, -0.0027, -0.0003],\n",
            "        [-0.0705,  0.0000, -0.0751, -0.0833, -0.0162],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0006, -0.0341, -0.0899, -0.0629, -0.0493],\n",
            "        [-0.0099,  0.0000, -0.0312,  0.0000,  0.0000],\n",
            "        [-0.0491, -0.0137, -0.0178,  0.0000,  0.0000],\n",
            "        [-0.0316, -0.0314, -0.0587, -0.0450, -0.0549],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0246, -0.0380, -0.0696, -0.0303, -0.0166],\n",
            "        [-0.0640, -0.0221, -0.0084,  0.0000,  0.0000],\n",
            "        [-0.0127, -0.0272,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0066, -0.0303, -0.0326, -0.0519, -0.0194],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0454, -0.0154, -0.0464, -0.0564, -0.0077],\n",
            "        [-0.0698, -0.0411,  0.0000,  0.0000, -0.0242],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.1043, -0.0353, -0.0029, -0.0450, -0.0376],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0146, -0.0154, -0.0192,  0.0000,  0.0000],\n",
            "        [-0.0308,  0.0000, -0.0005,  0.0000, -0.0381],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000, -0.0120,  0.0000, -0.0001],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(*list(model.parameters()), sep=\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwMAPcNc04Ei",
        "outputId": "7e81cc4a-b924-4d34-c68a-35b01a748735"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.0411,  0.0403, -0.0381,  ...,  0.0070, -0.0098,  0.0361],\n",
            "        [ 0.0602, -0.0403,  0.0220,  ..., -0.0329,  0.0394, -0.0038],\n",
            "        [ 0.0049,  0.0048, -0.0598,  ..., -0.0116, -0.0454,  0.0693],\n",
            "        ...,\n",
            "        [-0.0292, -0.0112,  0.0322,  ..., -0.0356,  0.0140,  0.0085],\n",
            "        [ 0.0468,  0.0525, -0.0084,  ...,  0.0426,  0.0116,  0.0396],\n",
            "        [ 0.0223, -0.0123,  0.0297,  ...,  0.0247,  0.0149, -0.0177]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fit():\n",
        "    for epoch in range(epochs):\n",
        "        for ii in range((n - 1) // bs + 1):\n",
        "            start_idx = ii * bs \n",
        "            end_idx = start_idx + bs\n",
        "            yb = x_train[start_idx: end_idx]\n",
        "            yb = y_train[start_idx: end_idx]\n",
        "            pred = model(xb)\n",
        "            loss = loss_func(pred, yb)\n",
        "\n",
        "            loss.backward()\n",
        "            with torch.no_grad():\n",
        "                for p in model.parameters():\n",
        "                    p -= p.grad * lr\n",
        "                model.zero_grad()\n",
        "\n",
        "fit()"
      ],
      "metadata": {
        "id": "i_R1LK9s0-nC"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(accuracy(model(xb), yb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLuK5MIx3VWj",
        "outputId": "e879c7ec-ac03-4e46-e5a3-3c4802ac3514"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy comparison -  tensor([0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
            "        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0.,\n",
            "        0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
            "        1., 0., 1., 1., 1., 0., 1., 1., 0., 1.])\n",
            "tensor(0.5625)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap \n",
        "\n",
        "print(\"torch.nn.Modules:\", *textwrap.wrap(\", \".join(torch.nn.modules.__all__)), sep=\"\\n\\t\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zFQBx_F3Zuz",
        "outputId": "d29e8161-c5ba-4cb9-ffa3-03b8fd1522f5"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.nn.Modules:\n",
            "\tModule, Identity, Linear, Conv1d, Conv2d, Conv3d, ConvTranspose1d,\n",
            "\tConvTranspose2d, ConvTranspose3d, Threshold, ReLU, Hardtanh, ReLU6,\n",
            "\tSigmoid, Tanh, Softmax, Softmax2d, LogSoftmax, ELU, SELU, CELU, GLU,\n",
            "\tGELU, Hardshrink, LeakyReLU, LogSigmoid, Softplus, Softshrink,\n",
            "\tMultiheadAttention, PReLU, Softsign, Softmin, Tanhshrink, RReLU,\n",
            "\tL1Loss, NLLLoss, KLDivLoss, MSELoss, BCELoss, BCEWithLogitsLoss,\n",
            "\tNLLLoss2d, PoissonNLLLoss, CosineEmbeddingLoss, CTCLoss,\n",
            "\tHingeEmbeddingLoss, MarginRankingLoss, MultiLabelMarginLoss,\n",
            "\tMultiLabelSoftMarginLoss, MultiMarginLoss, SmoothL1Loss,\n",
            "\tGaussianNLLLoss, HuberLoss, SoftMarginLoss, CrossEntropyLoss,\n",
            "\tContainer, Sequential, ModuleList, ModuleDict, ParameterList,\n",
            "\tParameterDict, AvgPool1d, AvgPool2d, AvgPool3d, MaxPool1d, MaxPool2d,\n",
            "\tMaxPool3d, MaxUnpool1d, MaxUnpool2d, MaxUnpool3d, FractionalMaxPool2d,\n",
            "\tFractionalMaxPool3d, LPPool1d, LPPool2d, LocalResponseNorm,\n",
            "\tBatchNorm1d, BatchNorm2d, BatchNorm3d, InstanceNorm1d, InstanceNorm2d,\n",
            "\tInstanceNorm3d, LayerNorm, GroupNorm, SyncBatchNorm, Dropout,\n",
            "\tDropout1d, Dropout2d, Dropout3d, AlphaDropout, FeatureAlphaDropout,\n",
            "\tReflectionPad1d, ReflectionPad2d, ReflectionPad3d, ReplicationPad2d,\n",
            "\tReplicationPad1d, ReplicationPad3d, CrossMapLRN2d, Embedding,\n",
            "\tEmbeddingBag, RNNBase, RNN, LSTM, GRU, RNNCellBase, RNNCell, LSTMCell,\n",
            "\tGRUCell, PixelShuffle, PixelUnshuffle, Upsample, UpsamplingNearest2d,\n",
            "\tUpsamplingBilinear2d, PairwiseDistance, AdaptiveMaxPool1d,\n",
            "\tAdaptiveMaxPool2d, AdaptiveMaxPool3d, AdaptiveAvgPool1d,\n",
            "\tAdaptiveAvgPool2d, AdaptiveAvgPool3d, TripletMarginLoss, ZeroPad2d,\n",
            "\tConstantPad1d, ConstantPad2d, ConstantPad3d, Bilinear,\n",
            "\tCosineSimilarity, Unfold, Fold, AdaptiveLogSoftmaxWithLoss,\n",
            "\tTransformerEncoder, TransformerDecoder, TransformerEncoderLayer,\n",
            "\tTransformerDecoderLayer, Transformer, LazyLinear, LazyConv1d,\n",
            "\tLazyConv2d, LazyConv3d, LazyConvTranspose1d, LazyConvTranspose2d,\n",
            "\tLazyConvTranspose3d, LazyBatchNorm1d, LazyBatchNorm2d,\n",
            "\tLazyBatchNorm3d, LazyInstanceNorm1d, LazyInstanceNorm2d,\n",
            "\tLazyInstanceNorm3d, Flatten, Unflatten, Hardsigmoid, Hardswish, SiLU,\n",
            "\tMish, TripletMarginWithDistanceLoss, ChannelShuffle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MNISTLogistic(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__() \n",
        "        self.lin = nn.Linear(784, 10)\n",
        "\n",
        "    def forward(self, xb):\n",
        "        return self.lin(xb)"
      ],
      "metadata": {
        "id": "j6e9W6SY37ZQ"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MNISTLogistic()\n",
        "print(loss_func(model(xb), yb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6KYltO54bkp",
        "outputId": "72c18ba4-f798-40aa-e317-4450b726ef6d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-0.0012, grad_fn=<NegBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(*list(model.children()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DZArNjU4gJu",
        "outputId": "14168e01-733c-4a88-a476-d22f5439fb4b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear(in_features=784, out_features=10, bias=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(*list(model.parameters()), sep=\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPmtrPge4oKR",
        "outputId": "3ca40d75-0fdc-44ba-aca1-bce5cb48c453"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.0321, -0.0333,  0.0050,  ...,  0.0101,  0.0331, -0.0049],\n",
            "        [-0.0077, -0.0034,  0.0054,  ..., -0.0198,  0.0309, -0.0180],\n",
            "        [ 0.0281, -0.0311,  0.0048,  ..., -0.0281,  0.0283,  0.0092],\n",
            "        ...,\n",
            "        [-0.0223,  0.0130, -0.0346,  ..., -0.0071,  0.0277,  0.0103],\n",
            "        [-0.0292,  0.0346, -0.0226,  ..., -0.0108,  0.0044,  0.0176],\n",
            "        [-0.0288, -0.0064, -0.0314,  ...,  0.0090, -0.0227, -0.0341]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.0037, -0.0020, -0.0081,  0.0126,  0.0151, -0.0207,  0.0318, -0.0309,\n",
            "         0.0261, -0.0084], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Applying gradients with `torch.optim.Optimizer`"
      ],
      "metadata": {
        "id": "lhOdNQpd498I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim \n",
        "\n",
        "def configure_optimizer(model: nn.Module) -> optim.Optimizer:\n",
        "    return optim.Adam(model.parameters(), lr=3e-4)"
      ],
      "metadata": {
        "id": "swfe5vMo4wAR"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MNISTLogistic()\n",
        "opt = configure_optimizer(model)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for ii in range((n - 1) // bs + 1):\n",
        "        start_idx = ii * bs \n",
        "        end_idx = start_idx + bs \n",
        "        xb = x_train[start_idx: end_idx]\n",
        "        yb = y_train[start_idx: end_idx]\n",
        "        pred = model(xb)\n",
        "        loss = loss_func(pred, yb)\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "print(\"after training: \", loss_func(model(xb), yb), sep=\"\\n\\t\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yy1iz3lP5JPv",
        "outputId": "5695bc6e-0879-4546-a9c5-1d65cbab6d5c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "after training: \n",
            "\ttensor(-0.1129, grad_fn=<NegBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from text_recognizer.data.util import BaseDataset \n",
        "\n",
        "train_ds = BaseDataset(x_train, y_train)"
      ],
      "metadata": {
        "id": "JuFz4I9C57m2"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BaseDataset??"
      ],
      "metadata": {
        "id": "RxU07D_16XgV"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MNISTLogistic()\n",
        "opt = configure_optimizer(model)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for ii in range((n - 1) // bs + 1):\n",
        "        xb, yb = train_ds[ii * bs: ii * bs + bs]\n",
        "        pred = model(xb)\n",
        "        loss = loss_func(pred, yb)\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "print(loss_func(model(xb), yb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4JC_iYW6cxu",
        "outputId": "035adaf0-ea2c-4508-8dca-c154c3517e2c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0718, grad_fn=<NegBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Batching up data with `torch.utils.data.DataLoader`"
      ],
      "metadata": {
        "id": "MvGAcfff7xaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_ds = BaseDataset(x_train, y_train)\n",
        "train_dataloader = DataLoader(train_ds, batch_size = bs)"
      ],
      "metadata": {
        "id": "QghcUL-i7X9N"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(self: nn.Module, train_dataloader: DataLoader):\n",
        "    opt = configure_optimizer(self)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for xb, yb in train_dataloader:\n",
        "            pred = self(xb)\n",
        "            loss = loss_func(pred, yb)\n",
        "\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "\n",
        "MNISTLogistic.fit = fit "
      ],
      "metadata": {
        "id": "niyoCQfJ8tZD"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MNISTLogistic()\n",
        "\n",
        "model.fit(train_dataloader)\n",
        "\n",
        "print(loss_func(model(xb), yb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOP-UMjF9Icv",
        "outputId": "237343b5-7e45-4ce9-e129-08bfe4c04ae9"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-39.3669, grad_fn=<NegBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Swapping in another model"
      ],
      "metadata": {
        "id": "lmtjOL8c9kPI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from text_recognizer.models.mlp import MLP \n",
        "\n",
        "MLP.fit = fit"
      ],
      "metadata": {
        "id": "oTkJm04-9N4C"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MLP.forward??"
      ],
      "metadata": {
        "id": "TKZIgb2j9sAw"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MLP.__init__??"
      ],
      "metadata": {
        "id": "WYes99sN9tJ5"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MLP?"
      ],
      "metadata": {
        "id": "eNMhAjqZ-6Sf"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "digits_to_9 = list(range(10))\n",
        "data_config = {\"input_dims\": (784,), \"mapping\": {digit: str(digit) for digit in digits_to_9}}\n",
        "data_config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXwLYhzd92ft",
        "outputId": "ecd8e9b6-448e-478f-a010-d77327f6e114"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_dims': (784,),\n",
              " 'mapping': {0: '0',\n",
              "  1: '1',\n",
              "  2: '2',\n",
              "  3: '3',\n",
              "  4: '4',\n",
              "  5: '5',\n",
              "  6: '6',\n",
              "  7: '7',\n",
              "  8: '8',\n",
              "  9: '9'}}"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLP(data_config)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vp7RioNO-gDp",
        "outputId": "c2f18bd8-72de-4f88-e5f8-e222d7e4dbff"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (fc1): Linear(in_features=784, out_features=1024, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (fc2): Linear(in_features=1024, out_features=128, bias=True)\n",
              "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fc1.weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZZCVueE-i-0",
        "outputId": "d6b3cea0-d02e-4481-f1ce-8e4c9a387d01"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.0284, -0.0277,  0.0339,  ..., -0.0036,  0.0009,  0.0147],\n",
              "        [ 0.0134,  0.0039,  0.0168,  ..., -0.0168,  0.0210,  0.0280],\n",
              "        [-0.0311,  0.0021, -0.0269,  ..., -0.0355,  0.0220, -0.0293],\n",
              "        ...,\n",
              "        [-0.0294,  0.0124, -0.0340,  ...,  0.0169,  0.0009,  0.0283],\n",
              "        [-0.0285, -0.0297, -0.0071,  ..., -0.0136,  0.0251,  0.0095],\n",
              "        [ 0.0084, -0.0273,  0.0097,  ...,  0.0005,  0.0007,  0.0239]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "print(\"before training: \", loss_func(model(xb), yb))\n",
        "\n",
        "train_ds = BaseDataset(x_train, y_train)\n",
        "train_dataloader = DataLoader(train_ds, batch_size=bs)\n",
        "fit(model, train_dataloader)\n",
        "\n",
        "print(\"after training: \", loss_func(model(xb), yb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKQJq79q_DHX",
        "outputId": "a7ae1040-cee2-4215-cd36-d7ea74c46c16"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before training:  tensor(-0.0365, grad_fn=<NegBackward0>)\n",
            "after training:  tensor(-6013567., grad_fn=<NegBackward0>)\n",
            "CPU times: user 24 s, sys: 581 ms, total: 24.6 s\n",
            "Wall time: 24.6 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GphNFBEYA0zM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RExnDOHM_SpY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}