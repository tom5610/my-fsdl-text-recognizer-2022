{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tom5610/my-fsdl-text-recognizer-2022/blob/main/lab01/notebooks/c_lab01_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKfcRGYnyOxY"
      },
      "source": [
        "Lab 01: Deep Neural Networks in PyTorch\n",
        "\n",
        "Objective:\n",
        "* how to write a basic neural network from scatch in PyTorch\n",
        "* How the submodules of torch, like `torch.nn` and `torch.utils.data`, make writing performant neural network training and inference code easier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRH_STeCygfM"
      },
      "source": [
        "## Setup\n",
        "Below cell will run full environment setup in colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/tomlu/Workspace/my-fsdl-text-recognizer-2022/lab01\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "PosixPath('/Users/tomlu/Workspace/my-fsdl-text-recognizer-2022/lab01')"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "current_dir = Path.cwd()\n",
        "\n",
        "print(current_dir)\n",
        "\n",
        "lab_idx = 1\n",
        "lab_name = f\"lab{str(lab_idx).zfill(2)}\"\n",
        "my_fsdl = \"my-fsdl-text-recognizer-2022\"\n",
        "\n",
        "if current_dir.name == lab_name:\n",
        "    pass \n",
        "else:\n",
        "    os.chdir(f\"{current_dir}/{my_fsdl}/{lab_name}\")\n",
        "\n",
        "Path.cwd()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACyi8BTcz1nk"
      },
      "source": [
        "## Getting data and making Tensors\n",
        "\n",
        "before we can build a model, we need data. \n",
        "\n",
        "Use MNIST dataset of handwritten digits.\n",
        "\n",
        "The data used to train state-of-the-art models these days is generally too large to be stored on the disk of any single machine (to say nothing of the RAM!), so fetching data over a network is a common first step in model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        " # allow 'hot-reloading' of modules\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "# needed for inline plots in some contexts\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "iXAz4GGHzhy0"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path \n",
        "import requests\n",
        "\n",
        "def download_mnist(path):\n",
        "    url = \"https://github.com/pytorch/tutorials/raw/master/_static/\"\n",
        "    filename = \"mnist.pkl.gz\"\n",
        "\n",
        "    if not (path / filename).exists():\n",
        "        content = requests.get(url + filename).content\n",
        "        (path / filename).open(\"wb\").write(content)\n",
        "\n",
        "    return path / filename\n",
        "\n",
        "data_path = Path(\"data\") if Path(\"data\").exists() else Path(\"../data\")\n",
        "path = data_path / \"downloaded\" / \"vector-mnist\"\n",
        "path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "datafile = download_mnist(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "IUZckCJG39Nn"
      },
      "outputs": [],
      "source": [
        "import gzip\n",
        "import pickle \n",
        "\n",
        "def read_mnist(path):\n",
        "    with gzip.open(path, \"rb\") as f:\n",
        "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")\n",
        "    return x_train, y_train, x_valid, y_valid\n",
        "\n",
        "x_train, y_train, x_valid, y_valid = read_mnist(datafile)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "c_qrmLb14ZHk"
      },
      "outputs": [],
      "source": [
        "import torch \n",
        "\n",
        "x_train, y_train, x_valid, y_valid = map(\n",
        "    torch.tensor, (x_train, y_train, x_valid, y_valid)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJa0EXhb4ywJ",
        "outputId": "06ef34bb-4d0c-42ec-b261-c1720e3c7e31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
            "tensor([5, 0, 4,  ..., 8, 4, 8])\n"
          ]
        }
      ],
      "source": [
        "print(x_train, y_train, sep=\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbrD0gYi5eP6",
        "outputId": "f59c0b65-2f98-483e-b3ec-07f0e6b4851e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(5),\n",
              " tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0117, 0.0703, 0.4922, 0.6836, 0.6484,\n",
              "         0.9648, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1172, 0.3672,\n",
              "         0.6641, 0.9883, 0.9883, 0.8789, 0.9883, 0.7617, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.9297, 0.9883, 0.9883, 0.9883, 0.9883, 0.3633,\n",
              "         0.3203, 0.1523, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8555,\n",
              "         0.9883, 0.9883, 0.7734, 0.9648, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.3125, 0.4180, 0.9883, 0.0430, 0.1680,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0039, 0.9883, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9883, 0.0078,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.7422, 0.2734, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1367,\n",
              "         0.8789, 0.4219, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9375, 0.9883, 0.0977, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.1758, 0.9883, 0.5859, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3633, 0.9883,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.9883, 0.2500, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1797, 0.7148,\n",
              "         0.9883, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.1523, 0.8945, 0.9883, 0.9766, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0938, 0.8633, 0.9883,\n",
              "         0.9883, 0.3047, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0898, 0.8320, 0.9883, 0.9883, 0.3164, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0703, 0.8555, 0.9883, 0.9883,\n",
              "         0.3125, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.2148, 0.8828, 0.9883, 0.9883, 0.5195, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5312, 0.9883, 0.8281, 0.5156,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000]))"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train[0], x_train[0, ::2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARnhmks_5muZ",
        "outputId": "99a7b931-9065-4438-952a-1f24d8a9f969"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2, 1)"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.ndim, y_train.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inzqGjFF6Hj_",
        "outputId": "34ac8bc4-237e-4218-e9b2-f44346d1df1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([50000, 784])\n",
            "torch.Size([50000])\n"
          ]
        }
      ],
      "source": [
        "n, c = x_train.shape\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "id": "YGPKHIer6QvQ",
        "outputId": "0c9cd90f-a36f-4067-e8cc-ddf598506c8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(5)\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAB6ElEQVR4nO2TPaviQBSGZ0WDilEMSAoLsUglXEEUC/GjEGz8BRYqgoVF7INir4g/wBRBsBK0EgUbQRALLdJJUPEDBAnxAw0WQZwt3F3u7l7vJnerXe5TzrzzcGbOGQA++f9BEMTv9zebzXg8/rcug8GQzWbb7fZ6vYYQQgiXy+XHdSaTKRaL7fd7+DObzeZ1TC1T53a7E4lEKpXS6/UAgMvl0mg0JEna7XbD4RBBEMUFejwelmUhhJIkbbdbkiStVqtiyw9wHK/VaqvV6nQ6lctlp9Mp59TT6xuNxlAoVK/XURQFAEynU57nI5EIhmHj8VgURcUFRqPRyWQC30IUxW63azabFUvT6fRDIQhCq9UKBAIv3yFJUhAEhmHUarlN/obL5WIYplgs4jj++26lUoEQBoNBxcW+w0OayWSeBVQfkGIYBgA4HA6y0haLxefzEQTxTsZms53P59lsptPpZEn7/T6EsNfrPQsUCoXHfw+Hw7KMAIDRaLRYLLxe7y/rdrs9l8vxPH+73SCE+XxepZL9bhRFQQg5jut0OjRN0zQ9n8+Px+P1en1MGMdxFEVptVq5RgCARqNxOBzVapXn+dcDPxgMSqVSMpl8tOiPfHlzFUEQgiBQFGVZFgAgSdL9fldQ3Sf/Bl8By4oIeAWZBm0AAAAASUVORK5CYII=",
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=28x28>"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import random \n",
        "\n",
        "import wandb \n",
        "\n",
        "import text_recognizer.metadata.mnist as metadata\n",
        "\n",
        "idx = random.randint(0, len(x_train))\n",
        "example = x_train[idx]\n",
        "\n",
        "print(y_train[idx])\n",
        "wandb.Image(example.reshape(*metadata.DIMS)).image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4u1hTNXg9X8C"
      },
      "source": [
        "## Build a DNN using only `torch.Tensor` methods and Python\n",
        "\n",
        "### Defining the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "9W3QEa8K7HP8"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "weights = torch.randn(784, 10) / math.sqrt(784)\n",
        "weights.requires_grad_()\n",
        "bias = torch.zeros(10, requires_grad=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKWAt2Nd-GFY",
        "outputId": "8da73c48-f955-427e-9088-d37043499a3e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2, torch.Size([784, 10]))"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weights.ndim, weights.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "Mv6Lapqy-PRF"
      },
      "outputs": [],
      "source": [
        "def linear(x: torch.Tensor) -> torch.Tensor:\n",
        "    return x @ weights + bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWlrvcUtgFOz",
        "outputId": "e274198e-2216-48f9-e369-592ec665619f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.9195)\n",
            "tensor(0.9195)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(tensor([0.1766, 0.7578, 0.4366]), tensor([0.1783, 0.7263, 0.7731]))"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n = 3\n",
        "a = torch.rand(n)\n",
        "b = torch.rand(n)\n",
        "print(torch.matmul(a, b))\n",
        "print(a @ b)\n",
        "a, b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V91HqSTsgTvd",
        "outputId": "d3de4be9-055e-4711-fc26-4d58457260b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.40253448999999997"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "0.5367 * 0.0799 + 0.361 * 0.3948 + 0.3556 * 0.6106"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "xnit7vxEht4g"
      },
      "outputs": [],
      "source": [
        "a = torch.rand((3, 2))\n",
        "b = torch.rand((2, 2))\n",
        "result = a.mm(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIRk3B8rh8Ob",
        "outputId": "49bb48e7-a0bc-4d09-d1a6-f6eef91fd316"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[0.7620, 0.8836],\n",
              "         [0.3764, 0.2266],\n",
              "         [0.0316, 0.5442]]),\n",
              " tensor([[0.0317, 0.9464],\n",
              "         [0.3619, 0.1735]]),\n",
              " tensor([[0.3439, 0.8745],\n",
              "         [0.0939, 0.3955],\n",
              "         [0.1979, 0.1244]]))"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a, b, result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "jGQapurliM8t"
      },
      "outputs": [],
      "source": [
        "def log_softmax(x: torch.Tensor) -> torch.Tensor:\n",
        "    return x - torch.log(torch.sum(torch.exp(x), axis = 1))[:, None]\n",
        "\n",
        "def model(xb: torch.Tensor) -> torch.Tensor:\n",
        "    return log_softmax(linear(xb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YON-Yat8wQfs",
        "outputId": "4bc0b0b2-6929-469b-a3bd-ea7ab2bb58bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([-2.3677, -2.3937, -2.0894, -2.8503, -2.3935, -2.1285, -2.2074, -2.1515,\n",
            "        -2.3162, -2.3212], grad_fn=<SelectBackward0>) torch.Size([64, 10])\n"
          ]
        }
      ],
      "source": [
        "bs = 64 # batch size\n",
        "\n",
        "xb = x_train[0: bs] # a batch of inputs\n",
        "outs = model(xb)\n",
        "\n",
        "print(outs[0], outs.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32dBTixvxBJY"
      },
      "source": [
        "## Defining the loss and metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "X95ORSKUwjOI"
      },
      "outputs": [],
      "source": [
        "def accuracy(out: torch.Tensor, yb: torch.Tensor) -> torch.Tensor:\n",
        "    preds = torch.argmax(out, dim=1)\n",
        "    #print('accuracy comparison - ', (preds == yb).float())\n",
        "    return (preds == yb).float().mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bSqnMiVxST8",
        "outputId": "6c97810f-07e6-44b6-896c-9ec0695b11c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0781)\n"
          ]
        }
      ],
      "source": [
        "yb = y_train[0: bs]\n",
        "\n",
        "acc = accuracy(outs, yb)\n",
        "\n",
        "print(acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "bv4w1lzTxXsl"
      },
      "outputs": [],
      "source": [
        "def cross_entropy(output: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
        "    return -output[range(target.shape[0]), target].mean()\n",
        "\n",
        "loss_func = cross_entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d5O5Xzwz9ZN",
        "outputId": "fce13026-b631-4751-96b7-f453cf31bd92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.3807, grad_fn=<NegBackward0>) tensor(2.3026)\n"
          ]
        }
      ],
      "source": [
        "print(loss_func(outs, yb), -torch.log(torch.tensor(1 / 10)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlUw1Xs60Byd",
        "outputId": "9cc2b153-162d-4ce8-e388-a0ee2ecc16ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(-2.3026)"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.log(torch.tensor(1 / 10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "u2Hsq9960HKZ"
      },
      "outputs": [],
      "source": [
        "loss = loss_func(outs, yb)\n",
        "\n",
        "loss.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeBo3jhF0bLA",
        "outputId": "676dad1f-c43a-4f53-8531-76483b00c7e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
              " tensor([-0.0234, -0.0173,  0.0399, -0.0079, -0.0544,  0.0295, -0.0021,  0.0295,\n",
              "          0.0359, -0.0297]))"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weights.grad, bias.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALffB6Yt0zaF"
      },
      "source": [
        "## Defining and running the fitting loop\n",
        "\n",
        "We now have all the ingredients we need to fit a neural network to data:\n",
        "\n",
        "* data (x_train, y_train)\n",
        "* a network architecture with parameters (model, weights, and bias)\n",
        "* a loss_func to optimize (cross_entropy) that supports .backward computation of gradients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "z7XzK1Io0iTo"
      },
      "outputs": [],
      "source": [
        "lr = 0.5\n",
        "epochs = 2\n",
        "\n",
        "for epoch in range(epochs): # loop over the data repeatedly\n",
        "    for ii in range((n - 1) // bs + 1):\n",
        "        start_idx = ii * bs\n",
        "        end_idx = start_idx + bs\n",
        "\n",
        "        # pull batches from x and from y\n",
        "        xb = x_train[start_idx:end_idx]\n",
        "        yb = y_train[start_idx:end_idx]\n",
        "\n",
        "        # run model\n",
        "        pred = model(xb)\n",
        "\n",
        "        # get loss\n",
        "        loss = loss_func(pred, yb)\n",
        "\n",
        "        # calculate the gradients with a backwards pass\n",
        "        loss.backward()\n",
        "\n",
        "        # update the parameters\n",
        "        with torch.no_grad(): # we don't want to track gradients through this part!\n",
        "            # SGD learning rule: update with negative gradient scaled by lr\n",
        "            weights -= weights.grad * lr\n",
        "            bias -= bias.grad * lr\n",
        "\n",
        "            # achtung: PyTorch doesn't assume you're done with gradients\n",
        "            #.         until you say so -- by explicitly \"deleting\" them. i.e. setting the gradients to 0.\n",
        "            weights.grad.zero_()\n",
        "            bias.grad.zero_()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-LYqR5M2bld",
        "outputId": "fa0c8ec9-7b29-4cac-f4b9-e536bddbe666"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.1104, grad_fn=<NegBackward0>) tensor(0.7344)\n"
          ]
        }
      ],
      "source": [
        "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "id": "n28GLemQ27aX",
        "outputId": "5cbc1f86-b638-4e91-f3da-9841ad875f78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(3)\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAACIklEQVR4nO2UzcspYRjG5ygJIcW78JHPRkSSzMbCTikbkrK2lL/AQknNQlZqosiOJbOwsSWyYKGIN0KysKF8hWbGWUxnjuMw5u2sTuf8lnPd99X1PFfPAMB//no0Gg0EQQiCbDYbgiAIgmg0GgiCOBwOoVBIs/jtleB0OlEUFYvFT9XRaJTJZE6nE4ZhpVKJacxEIoEzYzqdGo1GRkkhCGq328fj0efzUR8DgcD1enW73SAI3g9ns9lIJPI+qUAgyOVyKIrq9foHCQTBWq12HzaVSjE5/SMikcjj8SSTyWq1Oh6PKbvr9VooFOh7+wmLxQqFQvF4fDabzWaz1Wr1cJWn06lcLpvN5i9Ek8vlr5qZTCbFYtFisbwM9EpQqVSTyYQgiN+l2+1WqVSGw+Gr3Zftk1itVrvdDgDAx8dHLBbj8XiU1Gw2XS4X/fp7/H4/hmHUJazX6z91JDEYDPv9/mumDodDIpHQz1it1l6vh+P4+XwOh8PvTS+Xy26343K59GMwDJNh6/X604Ff2mez2Xw+3+v10puq1er3ASlutxuO44vFwmQyPR2QSqUwDJN1YRgWDAbfm+bzefJcy+XS6/XabDZKEgqF0Wj0vv1ut8soKYfD6XQ61Np+v//8wWKxuH9Uw+FQqVQyMgUAQKfTzedzmr9nv99Pp9NyuZzG5MmLkslkEAQpFAry1yuTybRa7Xa7HQwGrVYLRdHD4cA04z/Jd+k4kkLZQAAhAAAAAElFTkSuQmCC",
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=28x28>"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "idx = random.randint(0, len(x_train))\n",
        "example = x_train[idx: idx+1]\n",
        "\n",
        "out = model(example)\n",
        "\n",
        "print(out.argmax())\n",
        "wandb.Image(example.reshape(28, 28)).image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "we4djKmg5ekB"
      },
      "source": [
        "## Refactoring with core `torch.nn` components\n",
        "\n",
        "\n",
        "### Using `torch.nn.functional` for stateless computation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "xJEDeN623W5-"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "loss_func = F.cross_entropy\n",
        "\n",
        "def model(xb):\n",
        "    return xb @ weights + bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBH72ULw52pw",
        "outputId": "85ac88c8-770f-4363-8582-bc231b140da1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.1104, grad_fn=<NllLossBackward0>) tensor(0.7344)\n"
          ]
        }
      ],
      "source": [
        "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_k238jB96JLI"
      },
      "source": [
        "### Using torch.nn.Module to define functions whose state is given by `torch.nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "PyklJuFL5-jG"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class MNISTLogistic(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__() # this is mandatory as nn.Module does import setup\n",
        "        self.weights = nn.Parameter(torch.randn(784, 10) / math.sqrt(784))\n",
        "        self.bias = nn.Parameter(torch.zeros(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHgDmZiI03t7",
        "outputId": "57ad962d-8e65-4ba7-8348-3afe01b26136"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0834, -0.5464,  0.2889,  0.0533, -0.0507,  0.4940, -0.3092,  0.1692,\n",
            "         -0.6899,  0.4079],\n",
            "        [ 0.2463, -0.1957,  0.4502, -0.1657, -0.2697,  0.0777, -0.1134,  0.1952,\n",
            "         -0.5677,  0.7868],\n",
            "        [ 0.2313,  0.3113, -0.2038, -0.1581,  0.2716,  0.5513, -0.1684, -0.1080,\n",
            "         -0.0918,  0.1137],\n",
            "        [ 0.3737, -0.3313,  0.5608,  0.0222, -0.2071,  0.1293, -0.6640, -0.0680,\n",
            "         -0.2028,  0.2594]], grad_fn=<SliceBackward0>)\n",
            "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 3.0972e-03,  3.3074e-03,  3.1322e-03, -2.6317e-02,  1.6509e-03],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 8.4705e-03, -9.2593e-03,  1.8322e-02, -2.3929e-02, -3.0582e-04],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [-4.1629e-02,  1.2979e-02, -2.5464e-02,  8.1089e-03, -1.9009e-02],\n",
            "        [ 1.6157e-02, -1.4964e-02, -1.7046e-02,  1.0068e-02,  6.5078e-03],\n",
            "        [ 3.4004e-03,  2.8174e-03,  1.9338e-03,  1.4891e-03,  2.1485e-03],\n",
            "        [-3.7338e-02,  3.6864e-02,  4.8445e-02, -6.6742e-03, -3.5961e-02],\n",
            "        [ 3.3795e-03,  1.8507e-03, -3.0833e-03,  1.4613e-03,  9.0002e-04],\n",
            "        [-6.4631e-02,  9.0175e-03, -2.2583e-02,  2.6126e-02, -3.2493e-02],\n",
            "        [-2.8349e-02,  7.2511e-03, -1.7408e-02,  7.8489e-03, -9.4564e-03],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [-5.2053e-05,  3.2242e-02,  1.8106e-02,  2.4969e-02, -2.6333e-03],\n",
            "        [ 2.7387e-03,  1.7368e-03, -2.0505e-02,  1.7277e-03,  1.7701e-03],\n",
            "        [-8.3424e-02,  2.0599e-03, -7.2271e-03,  7.0192e-03,  5.8500e-03],\n",
            "        [-2.9068e-02,  4.0294e-02, -4.4783e-02, -5.8595e-02,  4.4505e-03],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 6.4284e-02,  2.8235e-02, -3.4514e-02, -2.2928e-02, -1.4365e-02],\n",
            "        [-5.1078e-03,  3.6703e-03, -2.7858e-02,  3.2038e-03,  2.7210e-03],\n",
            "        [-3.9031e-02, -4.0720e-03, -1.0674e-02,  6.7300e-03,  4.4405e-03],\n",
            "        [ 5.2803e-03,  4.7958e-03, -2.9413e-02, -2.4204e-02, -3.5080e-02],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 1.2974e-02, -1.0565e-03, -4.2433e-02, -9.8051e-03,  7.4504e-04],\n",
            "        [-5.3245e-02, -1.0015e-02,  4.2901e-06,  7.4826e-03,  5.5263e-03],\n",
            "        [-9.1876e-03, -2.2815e-02,  3.7914e-03,  1.9005e-03,  1.5300e-03],\n",
            "        [ 2.3819e-02,  1.3315e-03, -9.0749e-03, -3.5188e-02, -2.1785e-03],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [-1.1271e-02,  1.8352e-02, -1.9793e-02, -3.3880e-02,  7.1990e-03],\n",
            "        [-4.1934e-02, -1.0976e-02,  2.0548e-02,  1.7478e-02, -1.1680e-02],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [-5.3523e-02,  1.9093e-02,  3.4566e-02, -1.1804e-02, -1.2553e-02],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [-9.5177e-03, -1.0350e-02, -1.4829e-02,  2.7144e-03,  2.1908e-03],\n",
            "        [-1.5142e-02,  1.4232e-02,  9.6263e-03,  1.0258e-02, -3.1634e-02],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 6.7472e-03,  5.8478e-03, -6.5622e-03,  3.9679e-03,  3.9526e-03],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])\n"
          ]
        }
      ],
      "source": [
        "def forward(self, xb:torch.Tensor) -> torch.Tensor:\n",
        "    return xb @ self.weights + self.bias\n",
        "\n",
        "MNISTLogistic.forward = forward\n",
        "\n",
        "model = MNISTLogistic()\n",
        "print(model(xb)[:4])\n",
        "loss = loss_func(model(xb), yb)\n",
        "loss.backward()\n",
        "print(model.weights.grad[::17, ::2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwMAPcNc04Ei",
        "outputId": "622efeb4-bac4-4bac-b6a7-f1d6574727ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.0195,  0.0107, -0.0931,  ...,  0.0036,  0.0170, -0.0368],\n",
            "        [-0.0468,  0.0315, -0.0002,  ...,  0.0761, -0.0128, -0.0358],\n",
            "        [-0.0209,  0.0382, -0.0646,  ...,  0.0108,  0.0632,  0.0409],\n",
            "        ...,\n",
            "        [-0.0134, -0.0681,  0.0277,  ...,  0.0562,  0.0365, -0.0399],\n",
            "        [ 0.0830, -0.0332, -0.0410,  ..., -0.0255,  0.0277,  0.0033],\n",
            "        [-0.0132, -0.0375,  0.0662,  ..., -0.0117, -0.0075,  0.0453]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "print(*list(model.parameters()), sep=\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "i_R1LK9s0-nC"
      },
      "outputs": [],
      "source": [
        "def fit():\n",
        "    for epoch in range(epochs):\n",
        "        for ii in range((n - 1) // bs + 1):\n",
        "            start_idx = ii * bs \n",
        "            end_idx = start_idx + bs\n",
        "            yb = x_train[start_idx: end_idx]\n",
        "            yb = y_train[start_idx: end_idx]\n",
        "            pred = model(xb)\n",
        "            loss = loss_func(pred, yb)\n",
        "\n",
        "            loss.backward()\n",
        "            with torch.no_grad():\n",
        "                for p in model.parameters():\n",
        "                    p -= p.grad * lr\n",
        "                model.zero_grad()\n",
        "\n",
        "fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLuK5MIx3VWj",
        "outputId": "d1c0a344-7ce9-4986-a5fa-50e6ac53e6b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.7812)\n"
          ]
        }
      ],
      "source": [
        "print(accuracy(model(xb), yb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zFQBx_F3Zuz",
        "outputId": "6d5c86a6-2e5a-461e-e9ee-dab4e2f5c792"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.nn.Modules:\n",
            "\tModule, Identity, Linear, Conv1d, Conv2d, Conv3d, ConvTranspose1d,\n",
            "\tConvTranspose2d, ConvTranspose3d, Threshold, ReLU, Hardtanh, ReLU6,\n",
            "\tSigmoid, Tanh, Softmax, Softmax2d, LogSoftmax, ELU, SELU, CELU, GLU,\n",
            "\tGELU, Hardshrink, LeakyReLU, LogSigmoid, Softplus, Softshrink,\n",
            "\tMultiheadAttention, PReLU, Softsign, Softmin, Tanhshrink, RReLU,\n",
            "\tL1Loss, NLLLoss, KLDivLoss, MSELoss, BCELoss, BCEWithLogitsLoss,\n",
            "\tNLLLoss2d, PoissonNLLLoss, CosineEmbeddingLoss, CTCLoss,\n",
            "\tHingeEmbeddingLoss, MarginRankingLoss, MultiLabelMarginLoss,\n",
            "\tMultiLabelSoftMarginLoss, MultiMarginLoss, SmoothL1Loss,\n",
            "\tGaussianNLLLoss, HuberLoss, SoftMarginLoss, CrossEntropyLoss,\n",
            "\tContainer, Sequential, ModuleList, ModuleDict, ParameterList,\n",
            "\tParameterDict, AvgPool1d, AvgPool2d, AvgPool3d, MaxPool1d, MaxPool2d,\n",
            "\tMaxPool3d, MaxUnpool1d, MaxUnpool2d, MaxUnpool3d, FractionalMaxPool2d,\n",
            "\tFractionalMaxPool3d, LPPool1d, LPPool2d, LocalResponseNorm,\n",
            "\tBatchNorm1d, BatchNorm2d, BatchNorm3d, InstanceNorm1d, InstanceNorm2d,\n",
            "\tInstanceNorm3d, LayerNorm, GroupNorm, SyncBatchNorm, Dropout,\n",
            "\tDropout1d, Dropout2d, Dropout3d, AlphaDropout, FeatureAlphaDropout,\n",
            "\tReflectionPad1d, ReflectionPad2d, ReflectionPad3d, ReplicationPad2d,\n",
            "\tReplicationPad1d, ReplicationPad3d, CrossMapLRN2d, Embedding,\n",
            "\tEmbeddingBag, RNNBase, RNN, LSTM, GRU, RNNCellBase, RNNCell, LSTMCell,\n",
            "\tGRUCell, PixelShuffle, PixelUnshuffle, Upsample, UpsamplingNearest2d,\n",
            "\tUpsamplingBilinear2d, PairwiseDistance, AdaptiveMaxPool1d,\n",
            "\tAdaptiveMaxPool2d, AdaptiveMaxPool3d, AdaptiveAvgPool1d,\n",
            "\tAdaptiveAvgPool2d, AdaptiveAvgPool3d, TripletMarginLoss, ZeroPad2d,\n",
            "\tConstantPad1d, ConstantPad2d, ConstantPad3d, Bilinear,\n",
            "\tCosineSimilarity, Unfold, Fold, AdaptiveLogSoftmaxWithLoss,\n",
            "\tTransformerEncoder, TransformerDecoder, TransformerEncoderLayer,\n",
            "\tTransformerDecoderLayer, Transformer, LazyLinear, LazyConv1d,\n",
            "\tLazyConv2d, LazyConv3d, LazyConvTranspose1d, LazyConvTranspose2d,\n",
            "\tLazyConvTranspose3d, LazyBatchNorm1d, LazyBatchNorm2d,\n",
            "\tLazyBatchNorm3d, LazyInstanceNorm1d, LazyInstanceNorm2d,\n",
            "\tLazyInstanceNorm3d, Flatten, Unflatten, Hardsigmoid, Hardswish, SiLU,\n",
            "\tMish, TripletMarginWithDistanceLoss, ChannelShuffle\n"
          ]
        }
      ],
      "source": [
        "import textwrap \n",
        "\n",
        "print(\"torch.nn.Modules:\", *textwrap.wrap(\", \".join(torch.nn.modules.__all__)), sep=\"\\n\\t\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "j6e9W6SY37ZQ"
      },
      "outputs": [],
      "source": [
        "class MNISTLogistic(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__() \n",
        "        self.lin = nn.Linear(784, 10)\n",
        "\n",
        "    def forward(self, xb):\n",
        "        return self.lin(xb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6KYltO54bkp",
        "outputId": "c2d93413-8e30-443c-aebd-e63f6de145a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.3278, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "model = MNISTLogistic()\n",
        "print(loss_func(model(xb), yb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DZArNjU4gJu",
        "outputId": "06c6d9d1-869e-4b5d-963b-ec767a01214b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear(in_features=784, out_features=10, bias=True)\n"
          ]
        }
      ],
      "source": [
        "print(*list(model.children()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPmtrPge4oKR",
        "outputId": "5a14b79d-af99-4cd1-8eba-02a9ac340928"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.0044, -0.0330,  0.0191,  ..., -0.0279,  0.0152, -0.0124],\n",
            "        [ 0.0236, -0.0334, -0.0067,  ..., -0.0039, -0.0261, -0.0018],\n",
            "        [-0.0292,  0.0273,  0.0199,  ..., -0.0113, -0.0087, -0.0325],\n",
            "        ...,\n",
            "        [ 0.0118, -0.0124,  0.0070,  ..., -0.0002,  0.0134,  0.0352],\n",
            "        [ 0.0227,  0.0122,  0.0182,  ...,  0.0352,  0.0163,  0.0142],\n",
            "        [ 0.0098,  0.0185,  0.0155,  ..., -0.0161, -0.0159, -0.0347]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0169, -0.0308,  0.0064, -0.0216, -0.0299, -0.0196, -0.0294,  0.0288,\n",
            "        -0.0056,  0.0298], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "print(*list(model.parameters()), sep=\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhOdNQpd498I"
      },
      "source": [
        "### Applying gradients with `torch.optim.Optimizer`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "swfe5vMo4wAR"
      },
      "outputs": [],
      "source": [
        "from torch import optim \n",
        "\n",
        "def configure_optimizer(model: nn.Module) -> optim.Optimizer:\n",
        "    return optim.Adam(model.parameters(), lr=3e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yy1iz3lP5JPv",
        "outputId": "5ed29bd7-3e36-423c-e7a2-e5cfa66eef69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "after training: \n",
            "\ttensor(2.3100, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "model = MNISTLogistic()\n",
        "opt = configure_optimizer(model)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for ii in range((n - 1) // bs + 1):\n",
        "        start_idx = ii * bs \n",
        "        end_idx = start_idx + bs \n",
        "        xb = x_train[start_idx: end_idx]\n",
        "        yb = y_train[start_idx: end_idx]\n",
        "        pred = model(xb)\n",
        "        loss = loss_func(pred, yb)\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "print(\"after training: \", loss_func(model(xb), yb), sep=\"\\n\\t\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "JuFz4I9C57m2"
      },
      "outputs": [],
      "source": [
        "from text_recognizer.data.util import BaseDataset \n",
        "\n",
        "train_ds = BaseDataset(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "RxU07D_16XgV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0;31mInit signature:\u001b[0m \u001b[0mBaseDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSource:\u001b[0m        \n",
            "\u001b[0;32mclass\u001b[0m \u001b[0mBaseDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Base Dataset class that simply processes data and targets through optional transforms.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m    Read more: https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m    Parameters\u001b[0m\n",
            "\u001b[0;34m    ----------\u001b[0m\n",
            "\u001b[0;34m    data\u001b[0m\n",
            "\u001b[0;34m        commonly these are torch tensors, numpy arrays, or PIL Images\u001b[0m\n",
            "\u001b[0;34m    targets\u001b[0m\n",
            "\u001b[0;34m        commonly these are torch tensors or numpy arrays\u001b[0m\n",
            "\u001b[0;34m    transform\u001b[0m\n",
            "\u001b[0;34m        function that takes a datum and returns the same\u001b[0m\n",
            "\u001b[0;34m    target_transform\u001b[0m\n",
            "\u001b[0;34m        function that takes a target and returns the same\u001b[0m\n",
            "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequenceOrTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mtargets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequenceOrTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mtarget_transform\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data and targets must be of equal length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Return length of the dataset.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"\u001b[0m\n",
            "\u001b[0;34m        Return a datum and its target, after processing by transforms.\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Parameters\u001b[0m\n",
            "\u001b[0;34m        ----------\u001b[0m\n",
            "\u001b[0;34m        index\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m        Returns\u001b[0m\n",
            "\u001b[0;34m        -------\u001b[0m\n",
            "\u001b[0;34m        (datum, target)\u001b[0m\n",
            "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mdatum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;31m# if self.transform is not None:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;31m#     datum = self.transform(datum)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;31m# if self.target_transform is not None:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;31m#     target = self.target_transform(target)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mdatum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFile:\u001b[0m           ~/Workspace/my-fsdl-text-recognizer-2022/lab01/text_recognizer/data/util.py\n",
            "\u001b[0;31mType:\u001b[0m           type\n",
            "\u001b[0;31mSubclasses:\u001b[0m     \n"
          ]
        }
      ],
      "source": [
        "BaseDataset??"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4JC_iYW6cxu",
        "outputId": "b03df77a-d47c-497a-a14c-f32888685403"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.2858, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "model = MNISTLogistic()\n",
        "opt = configure_optimizer(model)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for ii in range((n - 1) // bs + 1):\n",
        "        xb, yb = train_ds[ii * bs: ii * bs + bs]\n",
        "        pred = model(xb)\n",
        "        loss = loss_func(pred, yb)\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "print(loss_func(model(xb), yb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvGAcfff7xaH"
      },
      "source": [
        "### Batching up data with `torch.utils.data.DataLoader`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "QghcUL-i7X9N"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_ds = BaseDataset(x_train, y_train)\n",
        "train_dataloader = DataLoader(train_ds, batch_size = bs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "niyoCQfJ8tZD"
      },
      "outputs": [],
      "source": [
        "def fit(self: nn.Module, train_dataloader: DataLoader):\n",
        "    opt = configure_optimizer(self)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for xb, yb in train_dataloader:\n",
        "            pred = self(xb)\n",
        "            loss = loss_func(pred, yb)\n",
        "\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "\n",
        "MNISTLogistic.fit = fit "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOP-UMjF9Icv",
        "outputId": "5214ba35-ba71-4255-f233-55e1a65d85e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.3824, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "model = MNISTLogistic()\n",
        "\n",
        "model.fit(train_dataloader)\n",
        "\n",
        "print(loss_func(model(xb), yb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmtjOL8c9kPI"
      },
      "source": [
        "### Swapping in another model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "oTkJm04-9N4C"
      },
      "outputs": [],
      "source": [
        "from text_recognizer.models.mlp import MLP \n",
        "\n",
        "MLP.fit = fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "TKZIgb2j9sAw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0;31mSignature:\u001b[0m \u001b[0mMLP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mDocstring:\u001b[0m\n",
            "Defines the computation performed at every call.\n",
            "\n",
            "Should be overridden by all subclasses.\n",
            "\n",
            ".. note::\n",
            "    Although the recipe for forward pass needs to be defined within\n",
            "    this function, one should call the :class:`Module` instance afterwards\n",
            "    instead of this since the former takes care of running the\n",
            "    registered hooks while the latter silently ignores them.\n",
            "\u001b[0;31mSource:\u001b[0m   \n",
            "    \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFile:\u001b[0m      ~/Workspace/my-fsdl-text-recognizer-2022/lab01/text_recognizer/models/mlp.py\n",
            "\u001b[0;31mType:\u001b[0m      function\n"
          ]
        }
      ],
      "source": [
        "MLP.forward??"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "WYes99sN9tJ5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0;31mSignature:\u001b[0m\n",
            "\u001b[0mMLP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0mdata_config\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNamespace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mDocstring:\u001b[0m Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
            "\u001b[0;31mSource:\u001b[0m   \n",
            "    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mdata_config\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNamespace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_config\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0minput_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_dims\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mapping\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mfc1_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fc1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFC1_DIM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mfc2_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fc2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFC2_DIM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mdropout_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fc_dropout\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFC_DROPOUT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc1_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropout_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfc1_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc2_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfc2_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFile:\u001b[0m      ~/Workspace/my-fsdl-text-recognizer-2022/lab01/text_recognizer/models/mlp.py\n",
            "\u001b[0;31mType:\u001b[0m      function\n"
          ]
        }
      ],
      "source": [
        "MLP.__init__??"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "eNMhAjqZ-6Sf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0;31mInit signature:\u001b[0m \u001b[0mMLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_config\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNamespace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mDocstring:\u001b[0m      Simple MLP suitable for recognizing single characters.\n",
            "\u001b[0;31mInit docstring:\u001b[0m Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
            "\u001b[0;31mFile:\u001b[0m           ~/Workspace/my-fsdl-text-recognizer-2022/lab01/text_recognizer/models/mlp.py\n",
            "\u001b[0;31mType:\u001b[0m           type\n",
            "\u001b[0;31mSubclasses:\u001b[0m     \n"
          ]
        }
      ],
      "source": [
        "MLP?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXwLYhzd92ft",
        "outputId": "537dbb22-deeb-43b9-fa3d-c670020ced1f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_dims': (784,),\n",
              " 'mapping': {0: '0',\n",
              "  1: '1',\n",
              "  2: '2',\n",
              "  3: '3',\n",
              "  4: '4',\n",
              "  5: '5',\n",
              "  6: '6',\n",
              "  7: '7',\n",
              "  8: '8',\n",
              "  9: '9'}}"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "digits_to_9 = list(range(10))\n",
        "data_config = {\"input_dims\": (784,), \"mapping\": {digit: str(digit) for digit in digits_to_9}}\n",
        "data_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vp7RioNO-gDp",
        "outputId": "816bc4f4-2136-415e-b789-81b3899cd5b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (fc1): Linear(in_features=784, out_features=1024, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (fc2): Linear(in_features=1024, out_features=128, bias=True)\n",
              "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = MLP(data_config)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZZCVueE-i-0",
        "outputId": "adb9a031-5dac-4649-8bad-bcb1ed7174d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.0333, -0.0181, -0.0020,  ..., -0.0313,  0.0300, -0.0191],\n",
              "        [ 0.0066, -0.0238, -0.0196,  ...,  0.0259, -0.0002, -0.0045],\n",
              "        [ 0.0074,  0.0105,  0.0324,  ..., -0.0196, -0.0105, -0.0287],\n",
              "        ...,\n",
              "        [ 0.0168,  0.0320, -0.0059,  ...,  0.0183, -0.0137,  0.0048],\n",
              "        [-0.0087,  0.0025,  0.0208,  ..., -0.0119,  0.0098,  0.0350],\n",
              "        [ 0.0282, -0.0066, -0.0211,  ..., -0.0160, -0.0070,  0.0144]],\n",
              "       requires_grad=True)"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fc1.weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKQJq79q_DHX",
        "outputId": "3ffbcde5-6757-48f4-a490-4436bb3f7218"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "before training:  tensor(2.3213, grad_fn=<NllLossBackward0>)\n",
            "after training:  tensor(0.1146, grad_fn=<NllLossBackward0>)\n",
            "CPU times: user 7.83 s, sys: 2.99 s, total: 10.8 s\n",
            "Wall time: 5.9 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "print(\"before training: \", loss_func(model(xb), yb))\n",
        "\n",
        "train_ds = BaseDataset(x_train, y_train)\n",
        "train_dataloader = DataLoader(train_ds, batch_size=bs)\n",
        "fit(model, train_dataloader)\n",
        "\n",
        "print(\"after training: \", loss_func(model(xb), yb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GphNFBEYA0zM"
      },
      "source": [
        "## Extra goodies: data organization, validation, and acceleration\n",
        "\n",
        "\n",
        "### Making the GPU go brrrr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RExnDOHM_SpY",
        "outputId": "3b97734c-1f2d-495c-c511-9adaafd85257"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Apple sillicon MPS\n"
          ]
        }
      ],
      "source": [
        "mps_available = torch.backends.mps.is_available() and torch.backends.mps.is_built()\n",
        "\n",
        "device = torch.device(\"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "    !nvidia-smi\n",
        "    device = torch.device(\"cuda\")\n",
        "elif mps_available:\n",
        "    print(\"Apple sillicon MPS\")\n",
        "    device = torch.device(\"mps\")\n",
        "else:\n",
        "    print(\":(\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0h8-DMNQBM1I",
        "outputId": "8a48cc84-e07d-4e83-a273-73cc1bb694e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='mps')"
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.to(device)\n",
        "\n",
        "loss_func(model(xb.to(device)), yb.to(device))\n",
        "\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "tZ55Oz0XKnGV"
      },
      "outputs": [],
      "source": [
        "def push_to_device(tensor):\n",
        "    return tensor.to(device)\n",
        "\n",
        "train_ds = BaseDataset(x_train, y_train, transform=push_to_device, target_transform=push_to_device)\n",
        "\n",
        "train_dataloader = DataLoader(train_ds, batch_size=bs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAr6Vn7KLHXH"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CFF5l2BMM7A",
        "outputId": "694ff0fb-541c-421e-e560-b4692d216beb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mps:0 mps:0\n"
          ]
        }
      ],
      "source": [
        "for xb, yb in train_dataloader:\n",
        "    print(xb.device, yb.device)\n",
        "    break;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVPXGY-MK905",
        "outputId": "ae9c0901-e9e1-41e0-a80d-edc028a78cf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.0923e-06, device='mps:0', grad_fn=<NllLossBackward0>)\n",
            "CPU times: user 21.9 s, sys: 6.88 s, total: 28.8 s\n",
            "Wall time: 22.6 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "model = MLP(data_config)\n",
        "model.to(device)\n",
        "\n",
        "model.fit(train_dataloader)\n",
        "\n",
        "print(loss_func(model(push_to_device(xb)), push_to_device(yb)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PO8dg2vTQa9Z"
      },
      "source": [
        "## Adding validation data and organizing data code with `DataModule`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "tW1y03ZGLcm9"
      },
      "outputs": [],
      "source": [
        "class MNISTDataModule:\n",
        "    url = \"https://github.com/pytorch/tutorials/raw/master/_static/\"\n",
        "    filename = \"mnist.pkl.gz\"\n",
        "\n",
        "    def __init__(self, dir, bs=32):\n",
        "        self.dir = dir\n",
        "        self.bs = bs\n",
        "        self.path = self.dir / self.filename\n",
        "\n",
        "    def prepare_data(self):\n",
        "        if not (self.path).exists():\n",
        "            content = requests.get(self.url + self.filename).content\n",
        "            self.path.open(\"wb\").write(content)\n",
        "\n",
        "    def setup(self):\n",
        "        with gzip.open(self.path, \"rb\") as f:\n",
        "            ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")\n",
        "\n",
        "        x_train, y_train, x_valid, y_valid = map(\n",
        "            torch.Tensor, (x_train, y_train, x_valid, y_valid)\n",
        "        )\n",
        "        # print(y_train[0], y_train[0].type)\n",
        "        # print(y_valid[0], y_valid[0].type)\n",
        "\n",
        "        self.train_ds = BaseDataset(x_train, y_train, transform=push_to_device, target_transform=push_to_device)\n",
        "        self.valid_ds = BaseDataset(x_valid, y_valid, transform=push_to_device, target_transform=push_to_device)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return torch.utils.data.DataLoader(self.train_ds, batch_size=self.bs, shuffle=True)\n",
        "\n",
        "    def valid_dataloader(self):\n",
        "        return torch.utils.data.DataLoader(self.valid_ds, batch_size=self.bs, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "wvuojgmInPFh"
      },
      "outputs": [],
      "source": [
        "def fit(self: nn.Module, datamodule):\n",
        "    datamodule.prepare_data()\n",
        "    datamodule.setup()\n",
        "\n",
        "    val_dataloader = datamodule.valid_dataloader()\n",
        "\n",
        "    self.eval()\n",
        "    with torch.no_grad():\n",
        "        valid_loss = sum(loss_func(self(xb), yb.type(torch.LongTensor).to(device)) for xb, yb in val_dataloader)\n",
        "\n",
        "    print(\"before start of training: \", valid_loss / len(val_dataloader))\n",
        "\n",
        "    opt = configure_optimizer(self)\n",
        "    train_dataloader = datamodule.train_dataloader()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        self.train()\n",
        "\n",
        "        for xb, yb in train_dataloader:\n",
        "            pred = self(xb)\n",
        "            loss = loss_func(pred, yb.type(torch.LongTensor).to(device))\n",
        "\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            valid_loss = sum(loss_func(self(xb), yb.type(torch.LongTensor).to(device)) for xb, yb in val_dataloader)\n",
        "        print(epoch, valid_loss / len(val_dataloader))\n",
        "\n",
        "MNISTLogistic.fit = fit\n",
        "MLP.fit = fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTXRis5xoVE5",
        "outputId": "ca2bb7dc-75dc-4c4b-c34e-be56b58d1905"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "before start of training:  tensor(2.2361, device='mps:0')\n",
            "0 tensor(23.1994, device='mps:0')\n",
            "1 tensor(28.8829, device='mps:0')\n",
            "2 tensor(34.7448, device='mps:0')\n",
            "3 tensor(inf, device='mps:0')\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/tomlu/Workspace/my-fsdl-text-recognizer-2022/lab01/notebooks/c_lab01_pytorch.ipynb Cell 80\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tomlu/Workspace/my-fsdl-text-recognizer-2022/lab01/notebooks/c_lab01_pytorch.ipynb#Y143sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tomlu/Workspace/my-fsdl-text-recognizer-2022/lab01/notebooks/c_lab01_pytorch.ipynb#Y143sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m datamodule \u001b[39m=\u001b[39m MNISTDataModule(\u001b[39mdir\u001b[39m\u001b[39m=\u001b[39mpath, bs\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/tomlu/Workspace/my-fsdl-text-recognizer-2022/lab01/notebooks/c_lab01_pytorch.ipynb#Y143sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(datamodule\u001b[39m=\u001b[39;49mdatamodule)\n",
            "\u001b[1;32m/Users/tomlu/Workspace/my-fsdl-text-recognizer-2022/lab01/notebooks/c_lab01_pytorch.ipynb Cell 80\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, datamodule)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tomlu/Workspace/my-fsdl-text-recognizer-2022/lab01/notebooks/c_lab01_pytorch.ipynb#Y143sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     loss \u001b[39m=\u001b[39m loss_func(pred, yb\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mLongTensor)\u001b[39m.\u001b[39mto(device))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tomlu/Workspace/my-fsdl-text-recognizer-2022/lab01/notebooks/c_lab01_pytorch.ipynb#Y143sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/tomlu/Workspace/my-fsdl-text-recognizer-2022/lab01/notebooks/c_lab01_pytorch.ipynb#Y143sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     opt\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tomlu/Workspace/my-fsdl-text-recognizer-2022/lab01/notebooks/c_lab01_pytorch.ipynb#Y143sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     opt\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tomlu/Workspace/my-fsdl-text-recognizer-2022/lab01/notebooks/c_lab01_pytorch.ipynb#Y143sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval()\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/torch-gpu/lib/python3.8/site-packages/torch/optim/optimizer.py:127\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/torch-gpu/lib/python3.8/site-packages/torch/optim/optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 23\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     24\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/torch-gpu/lib/python3.8/site-packages/torch/optim/adam.py:162\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m`requires_grad` is not supported for `step` in differentiable mode\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    160\u001b[0m             state_steps\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m--> 162\u001b[0m     adam(params_with_grad,\n\u001b[1;32m    163\u001b[0m          grads,\n\u001b[1;32m    164\u001b[0m          exp_avgs,\n\u001b[1;32m    165\u001b[0m          exp_avg_sqs,\n\u001b[1;32m    166\u001b[0m          max_exp_avg_sqs,\n\u001b[1;32m    167\u001b[0m          state_steps,\n\u001b[1;32m    168\u001b[0m          amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    169\u001b[0m          beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    170\u001b[0m          beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    171\u001b[0m          lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    172\u001b[0m          weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    173\u001b[0m          eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    174\u001b[0m          maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    175\u001b[0m          foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    176\u001b[0m          capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    177\u001b[0m          differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m    179\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/torch-gpu/lib/python3.8/site-packages/torch/optim/adam.py:220\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 220\u001b[0m func(params,\n\u001b[1;32m    221\u001b[0m      grads,\n\u001b[1;32m    222\u001b[0m      exp_avgs,\n\u001b[1;32m    223\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    224\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    225\u001b[0m      state_steps,\n\u001b[1;32m    226\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    227\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    228\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    229\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    230\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    231\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    232\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    233\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[1;32m    234\u001b[0m      differentiable\u001b[39m=\u001b[39;49mdifferentiable)\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/torch-gpu/lib/python3.8/site-packages/torch/optim/adam.py:277\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    274\u001b[0m     param \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mview_as_real(param)\n\u001b[1;32m    276\u001b[0m \u001b[39m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m exp_avg\u001b[39m.\u001b[39;49mmul_(beta1)\u001b[39m.\u001b[39;49madd_(grad, alpha\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m \u001b[39m-\u001b[39;49m beta1)\n\u001b[1;32m    278\u001b[0m exp_avg_sq\u001b[39m.\u001b[39mmul_(beta2)\u001b[39m.\u001b[39maddcmul_(grad, grad\u001b[39m.\u001b[39mconj(), value\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta2)\n\u001b[1;32m    280\u001b[0m \u001b[39mif\u001b[39;00m capturable \u001b[39mor\u001b[39;00m differentiable:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model = MLP(data_config)\n",
        "model.to(device)\n",
        "\n",
        "datamodule = MNISTDataModule(dir=path, bs=32)\n",
        "\n",
        "model.fit(datamodule=datamodule)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJ2PRgntuTks"
      },
      "source": [
        "### try out different hyperparameters for the `MLP` and for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNBZgbOsolUg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0;31mSignature:\u001b[0m\n",
            "\u001b[0mMLP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0mdata_config\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNamespace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mDocstring:\u001b[0m Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
            "\u001b[0;31mSource:\u001b[0m   \n",
            "    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mdata_config\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNamespace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_config\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0minput_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_dims\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mapping\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mfc1_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fc1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFC1_DIM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mfc2_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fc2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFC2_DIM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mdropout_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fc_dropout\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFC_DROPOUT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc1_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropout_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfc1_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc2_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfc2_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFile:\u001b[0m      ~/Workspace/my-fsdl-text-recognizer-2022/lab01/text_recognizer/models/mlp.py\n",
            "\u001b[0;31mType:\u001b[0m      function\n"
          ]
        }
      ],
      "source": [
        "MLP.__init__??"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8PtRoCYuZfD",
        "outputId": "0b7426ff-c839-4650-b696-9fba786189a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "before start of training:  tensor(2.3345, device='mps:0')\n",
            "0 tensor(20.1206, device='mps:0')\n",
            "1 tensor(21.7810, device='mps:0')\n",
            "2 tensor(19.4818, device='mps:0')\n",
            "3 tensor(8.8892, device='mps:0')\n",
            "4 tensor(21.8852, device='mps:0')\n",
            "5 tensor(16.5961, device='mps:0')\n",
            "6 tensor(19.4235, device='mps:0')\n",
            "7 tensor(19.7671, device='mps:0')\n",
            "CPU times: user 1min 22s, sys: 29.4 s, total: 1min 51s\n",
            "Wall time: 1min 27s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "from argparse import Namespace \n",
        "\n",
        "args = Namespace(epochs=2, bs=32) \n",
        "\n",
        "epochs = 8\n",
        "bs = 128 \n",
        "\n",
        "def configure_optimizer(model: nn.Module) -> optim.Optimizer:\n",
        "    return optim.Adam(model.parameters(), lr=3e-4)\n",
        "\n",
        "model = MLP(data_config, args=args)\n",
        "model.to(device)\n",
        "\n",
        "datamodule = MNISTDataModule(dir=path, bs=bs)\n",
        "\n",
        "model.fit(datamodule=datamodule)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qs6Emt9u5Op",
        "outputId": "903938a5-81ca-4db8-809c-5335dadb2f7e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0., device='mps:0')"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_dataloader = datamodule.valid_dataloader()\n",
        "valid_acc = sum(accuracy(model(xb), yb) for xb, yb in val_dataloader) / len(val_dataloader)\n",
        "valid_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kL0M7S5vlQS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMORCUalsTUEsPd0NBmaxiC",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "c_lab01_pytorch.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "7f9348cf459ed725a61e8ad1c80faeaacb2142bde10389f69ecee96b2c244d0d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
